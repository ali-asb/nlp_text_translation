{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10141464,"sourceType":"datasetVersion","datasetId":6259440}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pad_sequence\nfrom sklearn.model_selection import train_test_split\nimport string\n","metadata":{"id":"yNu6LixcUku4","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:13:07.638720Z","iopub.execute_input":"2024-12-08T21:13:07.638975Z","iopub.status.idle":"2024-12-08T21:13:07.643413Z","shell.execute_reply.started":"2024-12-08T21:13:07.638949Z","shell.execute_reply":"2024-12-08T21:13:07.642421Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"Cleaning the text","metadata":{}},{"cell_type":"code","source":"# Read and preprocess dataset\ndf = pd.read_csv('/kaggle/input/aaaaaa/sentences.csv')\ndf = df.dropna()\ndf = df.drop_duplicates()","metadata":{"id":"FyMAaaOHUreX","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:14:07.862002Z","iopub.execute_input":"2024-12-08T21:14:07.862640Z","iopub.status.idle":"2024-12-08T21:14:08.068746Z","shell.execute_reply.started":"2024-12-08T21:14:07.862604Z","shell.execute_reply":"2024-12-08T21:14:08.067927Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Remove punctuation\ndef remove_punctuation(text):\n    return text.translate(str.maketrans('', '', string.punctuation))\n\ndf['eng'] = df['eng'].apply(remove_punctuation)\ndf['darija'] = df['darija'].apply(remove_punctuation)","metadata":{"id":"2MfKiCEgU0PA","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:14:09.552563Z","iopub.execute_input":"2024-12-08T21:14:09.552950Z","iopub.status.idle":"2024-12-08T21:14:09.627665Z","shell.execute_reply.started":"2024-12-08T21:14:09.552918Z","shell.execute_reply":"2024-12-08T21:14:09.626798Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"Train-test split","metadata":{}},{"cell_type":"code","source":"\nSPLIT_SIZE = 0.2\ntrain_data, test_data = train_test_split(df, test_size=SPLIT_SIZE, random_state=4)\ntrain_data, val_data = train_test_split(train_data, test_size=SPLIT_SIZE, random_state=4)\n","metadata":{"id":"F2oEa287U7Ly","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:14:10.987071Z","iopub.execute_input":"2024-12-08T21:14:10.987927Z","iopub.status.idle":"2024-12-08T21:14:11.000133Z","shell.execute_reply.started":"2024-12-08T21:14:10.987893Z","shell.execute_reply":"2024-12-08T21:14:10.999261Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Tokenizing sentences.","metadata":{}},{"cell_type":"code","source":"\nX = train_data['eng'].str.lower().str.split().tolist()\nY = train_data['darija'].str.split().tolist()","metadata":{"id":"KBc5irnVU9Uq","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:14:12.606398Z","iopub.execute_input":"2024-12-08T21:14:12.606765Z","iopub.status.idle":"2024-12-08T21:14:12.635709Z","shell.execute_reply.started":"2024-12-08T21:14:12.606735Z","shell.execute_reply":"2024-12-08T21:14:12.634759Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Building vocabularies.","metadata":{}},{"cell_type":"code","source":"\nvocab_eng = set(word for sentence in X for word in sentence)\nvocab_dari = set(word for sentence in Y for word in sentence)\n\nword_to_ix_eng = {word: i for i, word in enumerate(vocab_eng, start=1)}\nword_to_ix_eng['<PAD>'] = 0\nword_to_ix_eng['<UNK>'] = len(word_to_ix_eng)\n\nword_to_ix_dari = {word: i for i, word in enumerate(vocab_dari, start=1)}\nword_to_ix_dari['<PAD>'] = 0\nword_to_ix_dari['<UNK>'] = len(word_to_ix_dari)","metadata":{"id":"BKMCU9EDU_8H","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:14:14.415001Z","iopub.execute_input":"2024-12-08T21:14:14.415361Z","iopub.status.idle":"2024-12-08T21:14:14.441523Z","shell.execute_reply.started":"2024-12-08T21:14:14.415327Z","shell.execute_reply":"2024-12-08T21:14:14.440667Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Prepare sequences","metadata":{}},{"cell_type":"code","source":"\ndef prepare_sequence(seq, to_ix):\n    return torch.tensor([to_ix.get(word, to_ix['<UNK>']) for word in seq], dtype=torch.long)\n\nX_train_encoded = [prepare_sequence(seq, word_to_ix_eng) for seq in X]\nY_train_encoded = [prepare_sequence(seq, word_to_ix_dari) for seq in Y]\n\nX_train_padded = pad_sequence(X_train_encoded, batch_first=True, padding_value=word_to_ix_eng[\"<PAD>\"])\nY_train_padded = pad_sequence(Y_train_encoded, batch_first=True, padding_value=word_to_ix_dari[\"<PAD>\"])\n","metadata":{"id":"obWwRixXVCAD","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:14:16.908830Z","iopub.execute_input":"2024-12-08T21:14:16.909651Z","iopub.status.idle":"2024-12-08T21:14:17.103745Z","shell.execute_reply.started":"2024-12-08T21:14:16.909619Z","shell.execute_reply":"2024-12-08T21:14:17.102784Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(f\"Shape of X_train_padded: {X_train_padded.shape}\")\nprint(f\"Shape of Y_train_padded: {Y_train_padded.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:14:37.976242Z","iopub.execute_input":"2024-12-08T21:14:37.976677Z","iopub.status.idle":"2024-12-08T21:14:37.982725Z","shell.execute_reply.started":"2024-12-08T21:14:37.976630Z","shell.execute_reply":"2024-12-08T21:14:37.981630Z"}},"outputs":[{"name":"stdout","text":"Shape of X_train_padded: torch.Size([8108, 38])\nShape of Y_train_padded: torch.Size([8108, 29])\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from torch.nn.functional import pad\n\n# Determine the max sequence length\nmax_seq_length = max(X_train_padded.size(1), Y_train_padded.size(1))\n\n# Pad English sequences to max_seq_length\nX_train_padded = pad(X_train_padded, (0, max_seq_length - X_train_padded.size(1)), value=word_to_ix_eng['<PAD>'])\n\n# Pad Darija sequences to max_seq_length\nY_train_padded = pad(Y_train_padded, (0, max_seq_length - Y_train_padded.size(1)), value=word_to_ix_dari['<PAD>'])\n\n# Check new shapes\nprint(f\"New Shape of X_train_padded: {X_train_padded.shape}\")\nprint(f\"New Shape of Y_train_padded: {Y_train_padded.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:15:31.709657Z","iopub.execute_input":"2024-12-08T21:15:31.710040Z","iopub.status.idle":"2024-12-08T21:15:31.718113Z","shell.execute_reply.started":"2024-12-08T21:15:31.710009Z","shell.execute_reply":"2024-12-08T21:15:31.717038Z"}},"outputs":[{"name":"stdout","text":"New Shape of X_train_padded: torch.Size([8108, 38])\nNew Shape of Y_train_padded: torch.Size([8108, 38])\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Hyperparameters","metadata":{}},{"cell_type":"code","source":"input_dim = len(word_to_ix_eng)\noutput_dim = len(word_to_ix_dari)\nembed_dim = 128  # Embedding dimension\nhidden_dim = 256  # Hidden state size of LSTM\nn_layers = 2  # Number of LSTM layers\nlearning_rate = 0.001\nnum_epochs = 10\nbatch_size = 64\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:20:58.162642Z","iopub.execute_input":"2024-12-08T21:20:58.163434Z","iopub.status.idle":"2024-12-08T21:20:58.168330Z","shell.execute_reply.started":"2024-12-08T21:20:58.163402Z","shell.execute_reply":"2024-12-08T21:20:58.167408Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"LSTM Model Implementation","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Define VanillaLSTMCell as per the given equations\nclass VanillaLSTMCell(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(VanillaLSTMCell, self).__init__()\n        self.hidden_size = hidden_size\n        \n        # Input gate parameters\n        self.Wxi = nn.Linear(input_size, hidden_size)\n        self.Whi = nn.Linear(hidden_size, hidden_size)\n        self.bi = nn.Parameter(torch.zeros(hidden_size))\n        \n        # Forget gate parameters\n        self.Wxf = nn.Linear(input_size, hidden_size)\n        self.Whf = nn.Linear(hidden_size, hidden_size)\n        self.bf = nn.Parameter(torch.zeros(hidden_size))\n        \n        # Output gate parameters\n        self.Wxo = nn.Linear(input_size, hidden_size)\n        self.Who = nn.Linear(hidden_size, hidden_size)\n        self.bo = nn.Parameter(torch.zeros(hidden_size))\n        \n        # Cell gate (g_t) parameters\n        self.Wxg = nn.Linear(input_size, hidden_size)\n        self.Whg = nn.Linear(hidden_size, hidden_size)\n        self.bc = nn.Parameter(torch.zeros(hidden_size))\n\n    def forward(self, x_t, prev_state):\n        h_prev, c_prev = prev_state\n        \n        # Compute gates\n        i_t = torch.sigmoid(self.Whi(h_prev) + self.Wxi(x_t) + self.bi)\n        f_t = torch.sigmoid(self.Whf(h_prev) + self.Wxf(x_t) + self.bf)\n        o_t = torch.sigmoid(self.Who(h_prev) + self.Wxo(x_t) + self.bo)\n        g_t = torch.tanh(self.Whg(h_prev) + self.Wxg(x_t) + self.bc)\n        \n        # Compute cell state and hidden state\n        c_t = f_t * c_prev + i_t * g_t\n        h_t = o_t * torch.tanh(g_t)\n        \n        return h_t, c_t\n\n# Define the Seq2Seq model using VanillaLSTMCell\nclass LSTMSeq2Seq(nn.Module):\n    def __init__(self, input_dim, output_dim, embed_dim, hidden_dim, n_layers):\n        super(LSTMSeq2Seq, self).__init__()\n        self.embed_dim = embed_dim\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n\n        self.encoder_embedding = nn.Embedding(input_dim, embed_dim)\n        self.decoder_embedding = nn.Embedding(output_dim, embed_dim)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n        # Encoder and Decoder use VanillaLSTMCell\n        self.encoder_cells = nn.ModuleList([VanillaLSTMCell(embed_dim if i == 0 else hidden_dim, hidden_dim) for i in range(n_layers)])\n        self.decoder_cells = nn.ModuleList([VanillaLSTMCell(embed_dim if i == 0 else hidden_dim, hidden_dim) for i in range(n_layers)])\n\n    def forward(self, source, target):\n        batch_size = source.size(0)\n        seq_len = target.size(1)\n\n        # Embedding for the encoder\n        encoder_input = self.encoder_embedding(source)\n\n        # Initialize states\n        h, c = [torch.zeros(batch_size, self.hidden_dim).to(encoder_input.device) for _ in range(self.n_layers)], \\\n               [torch.zeros(batch_size, self.hidden_dim).to(encoder_input.device) for _ in range(self.n_layers)]\n\n        # Encoder\n        for t in range(source.size(1)):\n            x_t = encoder_input[:, t, :]\n            for i, cell in enumerate(self.encoder_cells):\n                h[i], c[i] = cell(x_t, (h[i], c[i]))\n                x_t = h[i]  # Pass the hidden state to the next layer\n\n        # Initialize decoder states with encoder final states\n        decoder_input = self.decoder_embedding(target)\n        outputs = []\n        for t in range(seq_len):\n            x_t = decoder_input[:, t, :]\n            for i, cell in enumerate(self.decoder_cells):\n                h[i], c[i] = cell(x_t, (h[i], c[i]))\n                x_t = h[i]\n            outputs.append(self.fc(x_t))\n\n        # Stack outputs\n        outputs = torch.stack(outputs, dim=1)\n        return outputs\n\n# Define training parameters\ninput_dim = len(word_to_ix_eng)\noutput_dim = len(word_to_ix_dari)\nembed_dim = 128\nhidden_dim = 256\nn_layers = 2\nbatch_size = 32\nlearning_rate = 0.001\n\n# Dataset and DataLoader\ntrain_dataset = TensorDataset(X_train_padded, Y_train_padded)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# Model, Loss, and Optimizer\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = LSTMSeq2Seq(input_dim, output_dim, embed_dim, hidden_dim, n_layers).to(device)\ncriterion = nn.CrossEntropyLoss(ignore_index=word_to_ix_dari['<PAD>'])\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Training Loop\ndef train_model(model, train_loader, num_epochs=10):\n    model.train()\n    for epoch in range(num_epochs):\n        total_loss = 0\n        for source, target in train_loader:\n            source, target = source.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model(source, target[:, :-1])\n            loss = criterion(output.reshape(-1, output_dim), target[:, 1:].reshape(-1))\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n\ntrain_model(model, train_loader, num_epochs=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T22:06:05.757044Z","iopub.execute_input":"2024-12-08T22:06:05.757781Z","iopub.status.idle":"2024-12-08T22:12:38.926231Z","shell.execute_reply.started":"2024-12-08T22:06:05.757745Z","shell.execute_reply":"2024-12-08T22:12:38.925216Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 8.576262982811516\nEpoch 2, Loss: 7.838153232739666\nEpoch 3, Loss: 7.26143274157066\nEpoch 4, Loss: 6.389396898389801\nEpoch 5, Loss: 5.409328004506629\nEpoch 6, Loss: 4.463167216834121\nEpoch 7, Loss: 3.639712684736477\nEpoch 8, Loss: 2.960057603092644\nEpoch 9, Loss: 2.449950614313441\nEpoch 10, Loss: 2.0689985719252757\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Save the trained model\ntorch.save(model.state_dict(), \"hardcoded_lstm_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T22:14:56.901822Z","iopub.execute_input":"2024-12-08T22:14:56.902250Z","iopub.status.idle":"2024-12-08T22:14:56.949567Z","shell.execute_reply.started":"2024-12-08T22:14:56.902219Z","shell.execute_reply":"2024-12-08T22:14:56.948618Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"Training the Model","metadata":{}},{"cell_type":"code","source":"# Create DataLoader\nbatch_size = 32\ntrain_dataset = TensorDataset(X_train_padded, Y_train_padded)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# Define hyperparameters\ninput_dim = len(word_to_ix_eng)\noutput_dim = len(word_to_ix_dari)\nembed_dim = 256\nhidden_dim = 512\nn_layers = 2\nlearning_rate = 0.001\nnum_epochs = 20\n\n# Define the LSTM-based Seq2Seq model\nclass LSTMSeq2Seq(nn.Module):\n    def __init__(self, input_dim, output_dim, embed_dim, hidden_dim, n_layers):\n        super(LSTMSeq2Seq, self).__init__()\n        self.encoder_embedding = nn.Embedding(input_dim, embed_dim, padding_idx=0)\n        self.decoder_embedding = nn.Embedding(output_dim, embed_dim, padding_idx=0)\n        self.encoder_lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=n_layers, batch_first=True)\n        self.decoder_lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=n_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        # Encoder\n        embedded_src = self.encoder_embedding(src)\n        _, (hidden, cell) = self.encoder_lstm(embedded_src)\n        \n        # Decoder\n        trg_len = trg.size(1)\n        batch_size = trg.size(0)\n        trg_vocab_size = self.fc.out_features\n        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(trg.device)\n        \n        decoder_input = trg[:, 0].unsqueeze(1)  # Start token\n        for t in range(1, trg_len):\n            embedded_trg = self.decoder_embedding(decoder_input)\n            output, (hidden, cell) = self.decoder_lstm(embedded_trg, (hidden, cell))\n            pred = self.fc(output.squeeze(1))\n            outputs[:, t, :] = pred\n            \n            # Teacher forcing\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = pred.argmax(1)\n            decoder_input = trg[:, t].unsqueeze(1) if teacher_force else top1.unsqueeze(1)\n        \n        return outputs\n\n# Initialize model, criterion, optimizer\nmodel = LSTMSeq2Seq(input_dim, output_dim, embed_dim, hidden_dim, n_layers).to(device)\ncriterion = nn.CrossEntropyLoss(ignore_index=word_to_ix_dari['<PAD>'])\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Training and validation\nfor epoch in range(num_epochs):\n    # Training\n    model.train()\n    train_loss = 0\n    for src, trg in train_loader:\n        src, trg = src.to(device), trg.to(device)\n        optimizer.zero_grad()\n        output = model(src, trg)\n        \n        # Reshape output for loss calculation\n        output = output[:, 1:].reshape(-1, output_dim)\n        trg = trg[:, 1:].reshape(-1)\n        \n        # Compute loss and update weights\n        loss = criterion(output, trg)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss / len(train_loader):.4f}\")\n\n# Save the trained model\ntorch.save(model.state_dict(), \"lstm_seq2seq_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T21:30:15.374881Z","iopub.execute_input":"2024-12-08T21:30:15.375433Z","iopub.status.idle":"2024-12-08T21:39:22.612120Z","shell.execute_reply.started":"2024-12-08T21:30:15.375381Z","shell.execute_reply":"2024-12-08T21:39:22.610935Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20, Train Loss: 8.5023\nEpoch 2/20, Train Loss: 7.9829\nEpoch 3/20, Train Loss: 7.7891\nEpoch 4/20, Train Loss: 7.6187\nEpoch 5/20, Train Loss: 7.4422\nEpoch 6/20, Train Loss: 7.2629\nEpoch 7/20, Train Loss: 7.0694\nEpoch 8/20, Train Loss: 6.8755\nEpoch 9/20, Train Loss: 6.5985\nEpoch 10/20, Train Loss: 6.1829\nEpoch 11/20, Train Loss: 5.7548\nEpoch 12/20, Train Loss: 5.2243\nEpoch 13/20, Train Loss: 4.7434\nEpoch 14/20, Train Loss: 4.1681\nEpoch 15/20, Train Loss: 3.6505\nEpoch 16/20, Train Loss: 3.2617\nEpoch 17/20, Train Loss: 2.9764\nEpoch 18/20, Train Loss: 2.7335\nEpoch 19/20, Train Loss: 2.5964\nEpoch 20/20, Train Loss: 2.4479\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"test","metadata":{}},{"cell_type":"code","source":"# Create DataLoader\nbatch_size = 32\ntrain_dataset = TensorDataset(X_train_padded, Y_train_padded)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# Define hyperparameters\ninput_dim = len(word_to_ix_eng)\noutput_dim = len(word_to_ix_dari)\nembed_dim = 256\nhidden_dim = 512\nn_layers = 2\nlearning_rate = 0.001\nnum_epochs = 20","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the LSTM-based Seq2Seq model\nclass LSTMSeq2Seq(nn.Module):\n    def __init__(self, input_dim, output_dim, embed_dim, hidden_dim, n_layers):\n        super(LSTMSeq2Seq, self).__init__()\n        self.encoder_embedding = nn.Embedding(input_dim, embed_dim, padding_idx=0)\n        self.decoder_embedding = nn.Embedding(output_dim, embed_dim, padding_idx=0)\n        self.encoder_lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=n_layers, batch_first=True)\n        self.decoder_lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=n_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        # Encoder\n        embedded_src = self.encoder_embedding(src)\n        _, (hidden, cell) = self.encoder_lstm(embedded_src)\n        \n        # Decoder\n        trg_len = trg.size(1)\n        batch_size = trg.size(0)\n        trg_vocab_size = self.fc.out_features\n        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(trg.device)\n        \n        decoder_input = trg[:, 0].unsqueeze(1)  # Start token\n        for t in range(1, trg_len):\n            embedded_trg = self.decoder_embedding(decoder_input)\n            output, (hidden, cell) = self.decoder_lstm(embedded_trg, (hidden, cell))\n            pred = self.fc(output.squeeze(1))\n            outputs[:, t, :] = pred\n            \n            # Teacher forcing\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = pred.argmax(1)\n            decoder_input = trg[:, t].unsqueeze(1) if teacher_force else top1.unsqueeze(1)\n        \n        return outputs\n\n# Initialize model, criterion, optimizer\nmodel = LSTMSeq2Seq(input_dim, output_dim, embed_dim, hidden_dim, n_layers).to(device)\ncriterion = nn.CrossEntropyLoss(ignore_index=word_to_ix_dari['<PAD>'])\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training and validation\nfor epoch in range(num_epochs):\n    # Training\n    model.train()\n    train_loss = 0\n    for src, trg in train_loader:\n        src, trg = src.to(device), trg.to(device)\n        optimizer.zero_grad()\n        output = model(src, trg)\n        \n        # Reshape output for loss calculation\n        output = output[:, 1:].reshape(-1, output_dim)\n        trg = trg[:, 1:].reshape(-1)\n        \n        # Compute loss and update weights\n        loss = criterion(output, trg)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss / len(train_loader):.4f}\")\n\n# Save the trained model\ntorch.save(model.state_dict(), \"lstm_seq2seq_model.pth\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}