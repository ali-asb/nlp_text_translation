{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10141464,
          "sourceType": "datasetVersion",
          "datasetId": 6259440
        }
      ],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ],
      "metadata": {
        "id": "yNu6LixcUku4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:06:53.619024Z",
          "iopub.execute_input": "2024-12-09T22:06:53.619353Z",
          "iopub.status.idle": "2024-12-09T22:06:53.623717Z",
          "shell.execute_reply.started": "2024-12-09T22:06:53.619325Z",
          "shell.execute_reply": "2024-12-09T22:06:53.622852Z"
        }
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning the text"
      ],
      "metadata": {
        "id": "d9sA1QQJ75c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure proper NLTK setup\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "FyMAaaOHUreX",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:06:55.125404Z",
          "iopub.execute_input": "2024-12-09T22:06:55.126038Z",
          "iopub.status.idle": "2024-12-09T22:06:55.362768Z",
          "shell.execute_reply.started": "2024-12-09T22:06:55.126004Z",
          "shell.execute_reply": "2024-12-09T22:06:55.361812Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "135f17b2-1b9c-4eeb-e776-2e5af3676ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "df = pd.read_csv('sentences.csv').dropna().drop_duplicates()"
      ],
      "metadata": {
        "id": "2MfKiCEgU0PA",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:06:56.515062Z",
          "iopub.execute_input": "2024-12-09T22:06:56.515655Z",
          "iopub.status.idle": "2024-12-09T22:06:56.589748Z",
          "shell.execute_reply.started": "2024-12-09T22:06:56.515620Z",
          "shell.execute_reply": "2024-12-09T22:06:56.589095Z"
        }
      },
      "outputs": [],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-test split"
      ],
      "metadata": {
        "id": "128ai5X075c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "df['eng'] = df['eng'].apply(remove_punctuation)\n",
        "df['darija'] = df['darija'].apply(remove_punctuation)\n",
        "df = df[df['eng'].str.strip().astype(bool) & df['darija'].str.strip().astype(bool)]\n",
        "\n"
      ],
      "metadata": {
        "id": "F2oEa287U7Ly",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:06:58.479161Z",
          "iopub.execute_input": "2024-12-09T22:06:58.479942Z",
          "iopub.status.idle": "2024-12-09T22:06:58.491742Z",
          "shell.execute_reply.started": "2024-12-09T22:06:58.479910Z",
          "shell.execute_reply": "2024-12-09T22:06:58.490878Z"
        }
      },
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing sentences."
      ],
      "metadata": {
        "id": "J6hCzS0875c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "SPLIT_SIZE = 0.2\n",
        "train_data, test_data = train_test_split(df, test_size=SPLIT_SIZE, random_state=4)\n",
        "train_data, val_data = train_test_split(train_data, test_size=SPLIT_SIZE, random_state=4)\n"
      ],
      "metadata": {
        "id": "KBc5irnVU9Uq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:07:00.701678Z",
          "iopub.execute_input": "2024-12-09T22:07:00.702358Z",
          "iopub.status.idle": "2024-12-09T22:07:00.726762Z",
          "shell.execute_reply.started": "2024-12-09T22:07:00.702324Z",
          "shell.execute_reply": "2024-12-09T22:07:00.725795Z"
        }
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_lowercase(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "X = train_data['eng'].apply(tokenize_and_lowercase).tolist()\n",
        "Y = train_data['darija'].apply(tokenize_and_lowercase).tolist()\n",
        "X_val = val_data['eng'].apply(tokenize_and_lowercase).tolist()\n",
        "Y_val = val_data['darija'].apply(tokenize_and_lowercase).tolist()\n",
        "X_test = test_data['eng'].apply(tokenize_and_lowercase).tolist()\n",
        "Y_test = test_data['darija'].apply(tokenize_and_lowercase).tolist()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:07:02.807414Z",
          "iopub.execute_input": "2024-12-09T22:07:02.807996Z",
          "iopub.status.idle": "2024-12-09T22:07:02.813260Z",
          "shell.execute_reply.started": "2024-12-09T22:07:02.807962Z",
          "shell.execute_reply": "2024-12-09T22:07:02.812327Z"
        },
        "id": "Ywl-FTi675dA"
      },
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build vocabularies\n",
        "vocab_eng = set(word for sentence in X for word in sentence)\n",
        "vocab_dari = set(word for sentence in Y for word in sentence)\n",
        "\n",
        "word_to_ix_eng = {'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}\n",
        "word_to_ix_eng.update({word: i + len(word_to_ix_eng) for i, word in enumerate(vocab_eng)})\n",
        "\n",
        "word_to_ix_dari = {'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}\n",
        "word_to_ix_dari.update({word: i + len(word_to_ix_dari) for i, word in enumerate(vocab_dari)})\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:07:04.750226Z",
          "iopub.execute_input": "2024-12-09T22:07:04.750568Z",
          "iopub.status.idle": "2024-12-09T22:07:04.771342Z",
          "shell.execute_reply.started": "2024-12-09T22:07:04.750540Z",
          "shell.execute_reply": "2024-12-09T22:07:04.770400Z"
        },
        "id": "5ygNXlz475dC"
      },
      "outputs": [],
      "execution_count": 30
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building vocabularies."
      ],
      "metadata": {
        "id": "g74Jdvp275dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode sequences\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    return torch.tensor(\n",
        "        [to_ix['<SOS>']] + [to_ix.get(word, to_ix['<UNK>']) for word in seq] + [to_ix['<EOS>']],\n",
        "        dtype=torch.long\n",
        "    )\n",
        "\n",
        "X_train_encoded = [prepare_sequence(seq, word_to_ix_eng) for seq in X]\n",
        "Y_train_encoded = [prepare_sequence(seq, word_to_ix_dari) for seq in Y]\n",
        "X_val_encoded = [prepare_sequence(seq, word_to_ix_eng) for seq in X_val]\n",
        "Y_val_encoded = [prepare_sequence(seq, word_to_ix_dari) for seq in Y_val]\n"
      ],
      "metadata": {
        "id": "BKMCU9EDU_8H",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:07:06.762220Z",
          "iopub.execute_input": "2024-12-09T22:07:06.763031Z",
          "iopub.status.idle": "2024-12-09T22:07:07.015744Z",
          "shell.execute_reply.started": "2024-12-09T22:07:06.762998Z",
          "shell.execute_reply": "2024-12-09T22:07:07.014797Z"
        }
      },
      "outputs": [],
      "execution_count": 31
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pad sequences\n",
        "X_train_padded = pad_sequence(X_train_encoded, batch_first=True, padding_value=word_to_ix_eng['<PAD>'])\n",
        "Y_train_padded = pad_sequence(Y_train_encoded, batch_first=True, padding_value=word_to_ix_dari['<PAD>'])\n",
        "X_val_padded = pad_sequence(X_val_encoded, batch_first=True, padding_value=word_to_ix_eng['<PAD>'])\n",
        "Y_val_padded = pad_sequence(Y_val_encoded, batch_first=True, padding_value=word_to_ix_dari['<PAD>'])\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:07:09.014953Z",
          "iopub.execute_input": "2024-12-09T22:07:09.015271Z",
          "iopub.status.idle": "2024-12-09T22:07:09.021210Z",
          "shell.execute_reply.started": "2024-12-09T22:07:09.015246Z",
          "shell.execute_reply": "2024-12-09T22:07:09.020331Z"
        },
        "id": "b-CM6AlF75dD"
      },
      "outputs": [],
      "execution_count": 32
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and DataLoader\n",
        "train_dataset = TensorDataset(X_train_padded, Y_train_padded)\n",
        "val_dataset = TensorDataset(X_val_padded, Y_val_padded)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:07:11.553092Z",
          "iopub.execute_input": "2024-12-09T22:07:11.553416Z",
          "iopub.status.idle": "2024-12-09T22:07:11.558550Z",
          "shell.execute_reply.started": "2024-12-09T22:07:11.553392Z",
          "shell.execute_reply": "2024-12-09T22:07:11.557674Z"
        },
        "id": "lMFI4S-875dE"
      },
      "outputs": [],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": [
        "# Define AdvancedLSTMCell\n",
        "class AdvancedLSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(AdvancedLSTMCell, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.Wxi = nn.Linear(input_size, hidden_size, bias=False)\n",
        "        self.Whi = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.Wci = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.bi = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "        self.Wxf = nn.Linear(input_size, hidden_size, bias=False)\n",
        "        self.Whf = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.Wcf = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.bf = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "        self.Wxo = nn.Linear(input_size, hidden_size, bias=False)\n",
        "        self.Who = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.Wco = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.bo = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "        self.Wxg = nn.Linear(input_size, hidden_size, bias=False)\n",
        "        self.Whg = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.bc = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        h_prev, c_prev = hidden\n",
        "\n",
        "        i_t = torch.sigmoid(self.Wxi(x) + self.Whi(h_prev) + self.Wci * c_prev + self.bi)\n",
        "        f_t = torch.sigmoid(self.Wxf(x) + self.Whf(h_prev) + self.Wcf * c_prev + self.bf)\n",
        "        o_t = torch.sigmoid(self.Wxo(x) + self.Who(h_prev) + self.Wco * c_prev + self.bo)\n",
        "        g_t = torch.tanh(self.Wxg(x) + self.Whg(h_prev) + self.bc)\n",
        "\n",
        "        c_t = f_t * c_prev + i_t * g_t\n",
        "        h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        return h_t, c_t\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:07:13.456317Z",
          "iopub.execute_input": "2024-12-09T22:07:13.456652Z",
          "iopub.status.idle": "2024-12-09T22:07:13.486761Z",
          "shell.execute_reply.started": "2024-12-09T22:07:13.456622Z",
          "shell.execute_reply": "2024-12-09T22:07:13.485962Z"
        },
        "id": "jilTxC0I75dE"
      },
      "outputs": [],
      "execution_count": 34
    },
    {
      "cell_type": "code",
      "source": [
        "# Define AdvancedLSTM\n",
        "class AdvancedLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(AdvancedLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm_cell = AdvancedLSTMCell(hidden_size, hidden_size)\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x)\n",
        "        outputs = []\n",
        "        for t in range(embedded.size(1)):\n",
        "            hidden = self.lstm_cell(embedded[:, t, :], hidden)\n",
        "            outputs.append(hidden[0])\n",
        "        outputs = torch.stack(outputs, dim=1)\n",
        "        outputs = self.output_layer(outputs)\n",
        "        return outputs, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size, device):\n",
        "        return (torch.zeros(batch_size, self.hidden_size).to(device),\n",
        "                torch.zeros(batch_size, self.hidden_size).to(device))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T21:48:33.326766Z",
          "iopub.execute_input": "2024-12-09T21:48:33.327596Z",
          "iopub.status.idle": "2024-12-09T21:48:33.351983Z",
          "shell.execute_reply.started": "2024-12-09T21:48:33.327562Z",
          "shell.execute_reply": "2024-12-09T21:48:33.351019Z"
        },
        "id": "nbsxuKsR75dE"
      },
      "outputs": [],
      "execution_count": 35
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, Y_batch in data_loader:\n",
        "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "        hidden = model.init_hidden(X_batch.size(0), device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs, _ = model(X_batch, hidden)\n",
        "\n",
        "        # Truncate sequence lengths\n",
        "        min_seq_len = min(outputs.size(1), Y_batch.size(1))\n",
        "        outputs = outputs[:, :min_seq_len, :]\n",
        "        Y_batch = Y_batch[:, :min_seq_len]\n",
        "\n",
        "        # Reshape for loss computation\n",
        "        outputs = outputs.contiguous().view(-1, outputs.size(-1))  # Fixed here\n",
        "        Y_batch = Y_batch.contiguous().view(-1)  # Fixed here\n",
        "\n",
        "        loss = criterion(outputs, Y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, Y_batch in data_loader:\n",
        "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "            hidden = model.init_hidden(X_batch.size(0), device)\n",
        "            outputs, _ = model(X_batch, hidden)\n",
        "\n",
        "            # Truncate sequence lengths\n",
        "            min_seq_len = min(outputs.size(1), Y_batch.size(1))\n",
        "            outputs = outputs[:, :min_seq_len, :]\n",
        "            Y_batch = Y_batch[:, :min_seq_len]\n",
        "\n",
        "            # Reshape for loss computation\n",
        "            outputs = outputs.contiguous().view(-1, outputs.size(-1))  # Fixed here\n",
        "            Y_batch = Y_batch.contiguous().view(-1)  # Fixed here\n",
        "\n",
        "            loss = criterion(outputs, Y_batch)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data_loader)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:07:15.470829Z",
          "iopub.execute_input": "2024-12-09T22:07:15.471679Z",
          "iopub.status.idle": "2024-12-09T22:07:15.476042Z",
          "shell.execute_reply.started": "2024-12-09T22:07:15.471646Z",
          "shell.execute_reply": "2024-12-09T22:07:15.475117Z"
        },
        "id": "ubIh9CkI75dE"
      },
      "outputs": [],
      "execution_count": 36
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare sequences"
      ],
      "metadata": {
        "id": "LZffjW4O75dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model and parameters\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_size = len(word_to_ix_eng)\n",
        "hidden_size = 256\n",
        "output_size = len(word_to_ix_dari)\n",
        "\n",
        "model = AdvancedLSTM(input_size, hidden_size, output_size).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=word_to_ix_dari['<PAD>'])\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n"
      ],
      "metadata": {
        "id": "obWwRixXVCAD",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:07:17.882786Z",
          "iopub.execute_input": "2024-12-09T22:07:17.883433Z",
          "iopub.status.idle": "2024-12-09T22:07:18.253210Z",
          "shell.execute_reply.started": "2024-12-09T22:07:17.883398Z",
          "shell.execute_reply": "2024-12-09T22:07:18.252301Z"
        }
      },
      "outputs": [],
      "execution_count": 37
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "vaK9LekmdK9K"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T22:07:20.165412Z",
          "iopub.execute_input": "2024-12-09T22:07:20.166243Z",
          "iopub.status.idle": "2024-12-09T22:07:20.180243Z",
          "shell.execute_reply.started": "2024-12-09T22:07:20.166175Z",
          "shell.execute_reply": "2024-12-09T22:07:20.179062Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYSvSOeV75dF",
        "outputId": "d5bece8d-2b06-4786-f110-0e7d22148cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "Train Loss: 6.0958\n",
            "Validation Loss: 5.7569\n",
            "Epoch 2/20\n",
            "Train Loss: 5.1583\n",
            "Validation Loss: 5.6772\n",
            "Epoch 3/20\n",
            "Train Loss: 4.5618\n",
            "Validation Loss: 5.7046\n",
            "Epoch 4/20\n",
            "Train Loss: 3.9501\n",
            "Validation Loss: 5.7485\n",
            "Epoch 5/20\n",
            "Train Loss: 3.3855\n",
            "Validation Loss: 5.8525\n",
            "Epoch 6/20\n",
            "Train Loss: 2.8875\n",
            "Validation Loss: 5.9320\n",
            "Epoch 7/20\n",
            "Train Loss: 2.4726\n",
            "Validation Loss: 6.0326\n",
            "Epoch 8/20\n",
            "Train Loss: 2.1565\n",
            "Validation Loss: 6.1812\n",
            "Epoch 9/20\n",
            "Train Loss: 1.9156\n",
            "Validation Loss: 6.2726\n",
            "Epoch 10/20\n",
            "Train Loss: 1.7295\n",
            "Validation Loss: 6.3668\n",
            "Epoch 11/20\n",
            "Train Loss: 1.5773\n",
            "Validation Loss: 6.4389\n",
            "Epoch 12/20\n",
            "Train Loss: 1.4599\n",
            "Validation Loss: 6.5376\n",
            "Epoch 13/20\n",
            "Train Loss: 1.3626\n",
            "Validation Loss: 6.6071\n",
            "Epoch 14/20\n",
            "Train Loss: 1.2867\n",
            "Validation Loss: 6.6889\n",
            "Epoch 15/20\n",
            "Train Loss: 1.2230\n",
            "Validation Loss: 6.7718\n",
            "Epoch 16/20\n",
            "Train Loss: 1.1745\n",
            "Validation Loss: 6.8536\n",
            "Epoch 17/20\n",
            "Train Loss: 1.1369\n",
            "Validation Loss: 6.8577\n",
            "Epoch 18/20\n",
            "Train Loss: 1.1088\n",
            "Validation Loss: 6.9712\n",
            "Epoch 19/20\n",
            "Train Loss: 1.0810\n",
            "Validation Loss: 6.9983\n",
            "Epoch 20/20\n",
            "Train Loss: 1.0625\n",
            "Validation Loss: 7.0872\n"
          ]
        }
      ],
      "execution_count": 38
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"advanced_lstm_translation_model.pth\")\n"
      ],
      "metadata": {
        "id": "klxph6BtgtxT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "def test_model(model, data_loader, word_to_ix, ix_to_word, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, _ in data_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            hidden = model.init_hidden(X_batch.size(0), device)\n",
        "            outputs, _ = model(X_batch, hidden)\n",
        "            outputs = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "            for output_seq in outputs:\n",
        "                translated_sentence = [\n",
        "                    ix_to_word[ix.item()] for ix in output_seq if ix.item() not in {word_to_ix['<PAD>'], word_to_ix['<SOS>'], word_to_ix['<EOS>']}\n",
        "                ]\n",
        "                predictions.append(\" \".join(translated_sentence))\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "LEfpxKoSgwOy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create reverse mappings for decoding\n",
        "ix_to_word_eng = {ix: word for word, ix in word_to_ix_eng.items()}\n",
        "ix_to_word_dari = {ix: word for word, ix in word_to_ix_dari.items()}\n",
        "\n",
        "# Prepare test DataLoader\n",
        "X_test_encoded = [prepare_sequence(seq, word_to_ix_eng) for seq in X_test]\n",
        "Y_test_encoded = [prepare_sequence(seq, word_to_ix_dari) for seq in Y_test]\n",
        "X_test_padded = pad_sequence(X_test_encoded, batch_first=True, padding_value=word_to_ix_eng['<PAD>'])\n",
        "Y_test_padded = pad_sequence(Y_test_encoded, batch_first=True, padding_value=word_to_ix_dari['<PAD>'])\n",
        "test_dataset = TensorDataset(X_test_padded, Y_test_padded)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "qoxEQjTdgyiN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "test_predictions = test_model(model, test_loader, word_to_ix_dari, ix_to_word_dari, device)\n",
        "\n",
        "# Print a few test results\n",
        "for i in range(5):\n",
        "    print(f\"Original: {' '.join(X_test[i])}\")\n",
        "    print(f\"Predicted: {test_predictions[i]}\")\n",
        "    print(f\"Actual: {' '.join(Y_test[i])}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXysIkjhg0cs",
        "outputId": "b6cae4bc-3819-443e-952a-18c20df4b5ac"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: theres creepers everywhere\n",
            "Predicted: kayn kayn lblays bzaf\n",
            "Actual: kaynin chmakriya fin ma mchiti\n",
            "\n",
            "Original: eight books\n",
            "Predicted: tmnya tlktouba\n",
            "Actual: tmnya t lktouba\n",
            "\n",
            "Original: and working for you in particular\n",
            "Predicted: o kant ou dakchi\n",
            "Actual: olkhdma 3ndak 3la wjah lkhosos\n",
            "\n",
            "Original: unless we ask them to bring some with them\n",
            "Predicted: ma3ada imkan bzzaf o s3ib o o dyal dyal\n",
            "Actual: ma3ada ila guelna lihom yjibo chwia m3ahom\n",
            "\n",
            "Original: he has\n",
            "Predicted: 3ndo ch3er\n",
            "Actual: aando\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "test_predictions = test_model(model, test_loader, word_to_ix_dari, ix_to_word_dari, device)\n",
        "\n",
        "# Print a few test results\n",
        "for i in range(10):\n",
        "    print(f\"Original: {' '.join(X_test[i])}\")\n",
        "    print(f\"Predicted: {test_predictions[i]}\")\n",
        "    print(f\"Actual: {' '.join(Y_test[i])}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luGlf6R1g40w",
        "outputId": "25cd88e0-dbc1-40c9-b779-1a89e54eeba7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: theres creepers everywhere\n",
            "Predicted: kayn kayn lblays bzaf\n",
            "Actual: kaynin chmakriya fin ma mchiti\n",
            "\n",
            "Original: eight books\n",
            "Predicted: tmnya tlktouba\n",
            "Actual: tmnya t lktouba\n",
            "\n",
            "Original: and working for you in particular\n",
            "Predicted: o kant ou dakchi\n",
            "Actual: olkhdma 3ndak 3la wjah lkhosos\n",
            "\n",
            "Original: unless we ask them to bring some with them\n",
            "Predicted: ma3ada imkan bzzaf o s3ib o o dyal dyal\n",
            "Actual: ma3ada ila guelna lihom yjibo chwia m3ahom\n",
            "\n",
            "Original: he has\n",
            "Predicted: 3ndo ch3er\n",
            "Actual: aando\n",
            "\n",
            "Original: is there an emergency button\n",
            "Predicted: wach kayn chi chi chi\n",
            "Actual: wach kayn boton dyal tawari2\n",
            "\n",
            "Original: sorry i havent asked how your day was\n",
            "Predicted: sma7 liya hadi sawalt ach dyalk\n",
            "Actual: sma7 liya masawltkch kidaz nhark\n",
            "\n",
            "Original: i dont want\n",
            "Predicted: ana\n",
            "Actual: mabghitch\n",
            "\n",
            "Original: im worried about i seem to worry about everything\n",
            "Predicted: ana khayfa 3la ana\n",
            "Actual: ana khayf mn ban liya ana khayf 3la kolchi\n",
            "\n",
            "Original: its stupid to be lost when we have a good map\n",
            "Predicted: machi mkllkha annak annak karta zwina\n",
            "Actual: mn lghaba2 twadar mnin tkon 3andak kharita mazyana\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UrrO1hLHhPom"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}