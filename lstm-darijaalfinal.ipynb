{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10141464,"sourceType":"datasetVersion","datasetId":6259440}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pad_sequence\nfrom sklearn.model_selection import train_test_split\nimport string\n","metadata":{"id":"yNu6LixcUku4","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:06:53.619024Z","iopub.execute_input":"2024-12-09T22:06:53.619353Z","iopub.status.idle":"2024-12-09T22:06:53.623717Z","shell.execute_reply.started":"2024-12-09T22:06:53.619325Z","shell.execute_reply":"2024-12-09T22:06:53.622852Z"}},"outputs":[],"execution_count":116},{"cell_type":"markdown","source":"Cleaning the text","metadata":{}},{"cell_type":"code","source":"# Read and preprocess dataset\ndf = pd.read_csv('/kaggle/input/aaaaaa/sentences.csv')\ndf = df.dropna()\ndf = df.drop_duplicates()","metadata":{"id":"FyMAaaOHUreX","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:06:55.125404Z","iopub.execute_input":"2024-12-09T22:06:55.126038Z","iopub.status.idle":"2024-12-09T22:06:55.362768Z","shell.execute_reply.started":"2024-12-09T22:06:55.126004Z","shell.execute_reply":"2024-12-09T22:06:55.361812Z"}},"outputs":[],"execution_count":117},{"cell_type":"code","source":"# Remove punctuation\ndef remove_punctuation(text):\n    return text.translate(str.maketrans('', '', string.punctuation))\n\ndf['eng'] = df['eng'].apply(remove_punctuation)\ndf['darija'] = df['darija'].apply(remove_punctuation)","metadata":{"id":"2MfKiCEgU0PA","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:06:56.515062Z","iopub.execute_input":"2024-12-09T22:06:56.515655Z","iopub.status.idle":"2024-12-09T22:06:56.589748Z","shell.execute_reply.started":"2024-12-09T22:06:56.515620Z","shell.execute_reply":"2024-12-09T22:06:56.589095Z"}},"outputs":[],"execution_count":118},{"cell_type":"markdown","source":"Train-test split","metadata":{}},{"cell_type":"code","source":"\nSPLIT_SIZE = 0.2\ntrain_data, test_data = train_test_split(df, test_size=SPLIT_SIZE, random_state=4)\ntrain_data, val_data = train_test_split(train_data, test_size=SPLIT_SIZE, random_state=4)\n","metadata":{"id":"F2oEa287U7Ly","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:06:58.479161Z","iopub.execute_input":"2024-12-09T22:06:58.479942Z","iopub.status.idle":"2024-12-09T22:06:58.491742Z","shell.execute_reply.started":"2024-12-09T22:06:58.479910Z","shell.execute_reply":"2024-12-09T22:06:58.490878Z"}},"outputs":[],"execution_count":119},{"cell_type":"markdown","source":"Tokenizing sentences.","metadata":{}},{"cell_type":"code","source":"\nX = train_data['eng'].str.lower().str.split().tolist()\nY = train_data['darija'].str.split().tolist()","metadata":{"id":"KBc5irnVU9Uq","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:00.701678Z","iopub.execute_input":"2024-12-09T22:07:00.702358Z","iopub.status.idle":"2024-12-09T22:07:00.726762Z","shell.execute_reply.started":"2024-12-09T22:07:00.702324Z","shell.execute_reply":"2024-12-09T22:07:00.725795Z"}},"outputs":[],"execution_count":120},{"cell_type":"code","source":"# Afficher les 5 premiers cas\nprint(\"Premiers 5 éléments de X :\")\nfor i, sentence in enumerate(X[:5]):\n    print(f\"{i+1}: {sentence}\")\n\nprint(\"\\nPremiers 5 éléments de Y :\")\nfor i, sentence in enumerate(Y[:5]):\n    print(f\"{i+1}: {sentence}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:02.807414Z","iopub.execute_input":"2024-12-09T22:07:02.807996Z","iopub.status.idle":"2024-12-09T22:07:02.813260Z","shell.execute_reply.started":"2024-12-09T22:07:02.807962Z","shell.execute_reply":"2024-12-09T22:07:02.812327Z"}},"outputs":[{"name":"stdout","text":"Premiers 5 éléments de X :\n1: ['it', 'is', 'not', 'a', 'good', 'idea', 'for', 'me']\n2: ['indeed']\n3: ['but', 'you', 'also', 'like', 'a', 'few', 'glasses', 'of', 'good', 'french', 'wine', 'for', 'drinks']\n4: ['the', 'matter', 'is', 'clear']\n5: ['i', 'wish', 'i', 'could', 'transform', 'my', 'nightdreams', 'into', 'real', 'life', 'adventures']\n\nPremiers 5 éléments de Y :\n1: ['machi', 'blan', 'lia']\n2: ['fi3lan']\n3: ['walakin', '3ziz', '3lik', 'chi', 'kwiysat', 'dial', 'l', 'vin', 'dial', 'fransa', 'tchrbhom']\n4: ['l9aDiyya', 'bayna']\n5: ['makrehtch', 'koun', 'reje3t', '2a7lami', 'dial', 'lik', 'l79i9a']\n","output_type":"stream"}],"execution_count":121},{"cell_type":"code","source":"X_val = val_data['eng'].str.lower().str.split().tolist()\nY_val = val_data['darija'].str.split().tolist()\n\nX_test = test_data['eng'].str.lower().str.split().tolist()\nY_test = test_data['darija'].str.split().tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:04.750226Z","iopub.execute_input":"2024-12-09T22:07:04.750568Z","iopub.status.idle":"2024-12-09T22:07:04.771342Z","shell.execute_reply.started":"2024-12-09T22:07:04.750540Z","shell.execute_reply":"2024-12-09T22:07:04.770400Z"}},"outputs":[],"execution_count":122},{"cell_type":"markdown","source":"Building vocabularies.","metadata":{}},{"cell_type":"code","source":"\n# Combine all datasets (train, val, test) to build a unified vocabulary\nX_combined = train_data['eng'].str.lower().str.split().tolist() + val_data['eng'].str.lower().str.split().tolist()\nY_combined = train_data['darija'].str.split().tolist() + val_data['darija'].str.split().tolist()\n\n# Build vocabularies for English and Darija\nvocab_eng = set(word for sentence in X_combined for word in sentence)\nvocab_dari = set(word for sentence in Y_combined for word in sentence)\n\n# Create word-to-index mappings\nword_to_ix_eng = {word: i for i, word in enumerate(vocab_eng, start=1)}\nword_to_ix_eng['<PAD>'] = 0\nword_to_ix_eng['<UNK>'] = len(word_to_ix_eng)\n\nword_to_ix_dari = {word: i for i, word in enumerate(vocab_dari, start=1)}\nword_to_ix_dari['<PAD>'] = 0\nword_to_ix_dari['<UNK>'] = len(word_to_ix_dari)\n\n# Verify sizes of vocabularies\nprint(f\"English vocabulary size: {len(word_to_ix_eng)}\")\nprint(f\"Darija vocabulary size: {len(word_to_ix_dari)}\")","metadata":{"id":"BKMCU9EDU_8H","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:06.762220Z","iopub.execute_input":"2024-12-09T22:07:06.763031Z","iopub.status.idle":"2024-12-09T22:07:07.015744Z","shell.execute_reply.started":"2024-12-09T22:07:06.762998Z","shell.execute_reply":"2024-12-09T22:07:07.014797Z"}},"outputs":[{"name":"stdout","text":"English vocabulary size: 4977\nDarija vocabulary size: 13362\n","output_type":"stream"}],"execution_count":123},{"cell_type":"code","source":"# Afficher les 5 premiers éléments de word_to_ix_eng\nprint(\"5 premiers éléments de word_to_ix_eng :\")\nfor i, (word, index) in enumerate(word_to_ix_eng.items()):\n    print(f\"{word}: {index}\")\n    if i == 4:  # Stop après 5 éléments\n        break\n\n# Afficher les 5 premiers éléments de word_to_ix_dari\nprint(\"\\n5 premiers éléments de word_to_ix_dari :\")\nfor i, (word, index) in enumerate(word_to_ix_dari.items()):\n    print(f\"{word}: {index}\")\n    if i == 4:  # Stop après 5 éléments\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:09.014953Z","iopub.execute_input":"2024-12-09T22:07:09.015271Z","iopub.status.idle":"2024-12-09T22:07:09.021210Z","shell.execute_reply.started":"2024-12-09T22:07:09.015246Z","shell.execute_reply":"2024-12-09T22:07:09.020331Z"}},"outputs":[{"name":"stdout","text":"5 premiers éléments de word_to_ix_eng :\nduck: 1\nnowhere: 2\nopportunity: 3\nera: 4\nfamous: 5\n\n5 premiers éléments de word_to_ix_dari :\n3lihoum: 1\nsder: 2\nkaykhrj: 3\nkanakol: 4\nkant3elem: 5\n","output_type":"stream"}],"execution_count":124},{"cell_type":"code","source":"# Add SOS and EOS tokens\nword_to_ix_eng['<SOS>'] = len(word_to_ix_eng)\nword_to_ix_eng['<EOS>'] = len(word_to_ix_eng)\n\nword_to_ix_dari['<SOS>'] = len(word_to_ix_dari)\nword_to_ix_dari['<EOS>'] = len(word_to_ix_dari)\n\n# Verify updated vocabulary sizes\nprint(f\"Updated English vocabulary size: {len(word_to_ix_eng)}\")\nprint(f\"Updated Darija vocabulary size: {len(word_to_ix_dari)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:11.553092Z","iopub.execute_input":"2024-12-09T22:07:11.553416Z","iopub.status.idle":"2024-12-09T22:07:11.558550Z","shell.execute_reply.started":"2024-12-09T22:07:11.553392Z","shell.execute_reply":"2024-12-09T22:07:11.557674Z"}},"outputs":[{"name":"stdout","text":"Updated English vocabulary size: 4979\nUpdated Darija vocabulary size: 13364\n","output_type":"stream"}],"execution_count":125},{"cell_type":"code","source":"# Function to add SOS and EOS tokens\ndef add_sos_eos(sentence, sos_token='<SOS>', eos_token='<EOS>'):\n    return [sos_token] + sentence + [eos_token]\n\n# Add SOS and EOS tokens to train, val, and test datasets\nX = [add_sos_eos(sentence) for sentence in X]\nY = [add_sos_eos(sentence) for sentence in Y]\n\nX_val = [add_sos_eos(sentence) for sentence in X_val]\nY_val = [add_sos_eos(sentence) for sentence in Y_val]\n\nX_test = [add_sos_eos(sentence) for sentence in X_test]\nY_test = [add_sos_eos(sentence) for sentence in Y_test]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:13.456317Z","iopub.execute_input":"2024-12-09T22:07:13.456652Z","iopub.status.idle":"2024-12-09T22:07:13.486761Z","shell.execute_reply.started":"2024-12-09T22:07:13.456622Z","shell.execute_reply":"2024-12-09T22:07:13.485962Z"}},"outputs":[],"execution_count":126},{"cell_type":"code","source":"X_combined = [add_sos_eos(sentence) for sentence in X_combined]\nY_combined = [add_sos_eos(sentence) for sentence in Y_combined]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T21:48:33.326766Z","iopub.execute_input":"2024-12-09T21:48:33.327596Z","iopub.status.idle":"2024-12-09T21:48:33.351983Z","shell.execute_reply.started":"2024-12-09T21:48:33.327562Z","shell.execute_reply":"2024-12-09T21:48:33.351019Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"print(f\"Example processed sentence (English): {X[0]}\")\nprint(f\"Example processed sentence (Darija): {Y[0]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:15.470829Z","iopub.execute_input":"2024-12-09T22:07:15.471679Z","iopub.status.idle":"2024-12-09T22:07:15.476042Z","shell.execute_reply.started":"2024-12-09T22:07:15.471646Z","shell.execute_reply":"2024-12-09T22:07:15.475117Z"}},"outputs":[{"name":"stdout","text":"Example processed sentence (English): ['<SOS>', 'it', 'is', 'not', 'a', 'good', 'idea', 'for', 'me', '<EOS>']\nExample processed sentence (Darija): ['<SOS>', 'machi', 'blan', 'lia', '<EOS>']\n","output_type":"stream"}],"execution_count":127},{"cell_type":"markdown","source":"Prepare sequences","metadata":{}},{"cell_type":"code","source":"# Prepare sequences with SOS and EOS\ndef prepare_sequence(seq, to_ix):\n    return torch.tensor(\n        [to_ix[\"<SOS>\"]] + [to_ix.get(word, to_ix[\"<UNK>\"]) for word in seq] + [to_ix[\"<EOS>\"]],\n        dtype=torch.long\n    )\n\n# Encode and pad sequences for training\nX_train_encoded = [prepare_sequence(seq, word_to_ix_eng) for seq in X]\nY_train_encoded = [prepare_sequence(seq, word_to_ix_dari) for seq in Y]\n\nX_train_padded = pad_sequence(X_train_encoded, batch_first=True, padding_value=word_to_ix_eng[\"<PAD>\"])\nY_train_padded = pad_sequence(Y_train_encoded, batch_first=True, padding_value=word_to_ix_dari[\"<PAD>\"])\n\n# Encode and pad sequences for validation\nX_val_encoded = [prepare_sequence(seq, word_to_ix_eng) for seq in X_val]\nY_val_encoded = [prepare_sequence(seq, word_to_ix_dari) for seq in Y_val]\n\nX_val_padded = pad_sequence(X_val_encoded, batch_first=True, padding_value=word_to_ix_eng[\"<PAD>\"])\nY_val_padded = pad_sequence(Y_val_encoded, batch_first=True, padding_value=word_to_ix_dari[\"<PAD>\"])\n\n# Encode and pad sequences for testing\nX_test_encoded = [prepare_sequence(seq, word_to_ix_eng) for seq in X_test]\nY_test_encoded = [prepare_sequence(seq, word_to_ix_dari) for seq in Y_test]\n\nX_test_padded = pad_sequence(X_test_encoded, batch_first=True, padding_value=word_to_ix_eng[\"<PAD>\"])\nY_test_padded = pad_sequence(Y_test_encoded, batch_first=True, padding_value=word_to_ix_dari[\"<PAD>\"])\n\n# Print shapes for sanity check\nprint(f\"X_train_padded: {X_train_padded.shape}, Y_train_padded: {Y_train_padded.shape}\")\nprint(f\"X_val_padded: {X_val_padded.shape}, Y_val_padded: {Y_val_padded.shape}\")\nprint(f\"X_test_padded: {X_test_padded.shape}, Y_test_padded: {Y_test_padded.shape}\")\n","metadata":{"id":"obWwRixXVCAD","trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:17.882786Z","iopub.execute_input":"2024-12-09T22:07:17.883433Z","iopub.status.idle":"2024-12-09T22:07:18.253210Z","shell.execute_reply.started":"2024-12-09T22:07:17.883398Z","shell.execute_reply":"2024-12-09T22:07:18.252301Z"}},"outputs":[{"name":"stdout","text":"X_train_padded: torch.Size([8108, 42]), Y_train_padded: torch.Size([8108, 33])\nX_val_padded: torch.Size([2027, 35]), Y_val_padded: torch.Size([2027, 27])\nX_test_padded: torch.Size([2534, 35]), Y_test_padded: torch.Size([2534, 28])\n","output_type":"stream"}],"execution_count":128},{"cell_type":"code","source":"# Afficher les 5 premières séquences encodées pour X\nprint(\"5 premières séquences encodées de X_train_encoded :\")\nfor i in range(min(5, len(X_train_encoded))):\n    print(f\"Sequence {i + 1}: {X_train_encoded[i]}\")\n\n# Afficher les 5 premières séquences encodées pour Y\nprint(\"\\n5 premières séquences encodées de Y_train_encoded :\")\nfor i in range(min(5, len(Y_train_encoded))):\n    print(f\"Sequence {i + 1}: {Y_train_encoded[i]}\")\n\n# Afficher les 5 premières séquences padées pour X\nprint(\"\\n5 premières séquences padées de X_train_padded :\")\nfor i in range(min(5, len(X_train_padded))):\n    print(f\"Sequence {i + 1}: {X_train_padded[i].tolist()}\")\n\n# Afficher les 5 premières séquences padées pour Y\nprint(\"\\n5 premières séquences padées de Y_train_padded :\")\nfor i in range(min(5, len(Y_train_padded))):\n    print(f\"Sequence {i + 1}: {Y_train_padded[i].tolist()}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:20.165412Z","iopub.execute_input":"2024-12-09T22:07:20.166243Z","iopub.status.idle":"2024-12-09T22:07:20.180243Z","shell.execute_reply.started":"2024-12-09T22:07:20.166175Z","shell.execute_reply":"2024-12-09T22:07:20.179062Z"}},"outputs":[{"name":"stdout","text":"5 premières séquences encodées de X_train_encoded :\nSequence 1: tensor([4977, 4977, 2700, 1372, 1064, 3949, 4082, 4881, 3607, 4535, 4978, 4978])\nSequence 2: tensor([4977, 4977, 2242, 4978, 4978])\nSequence 3: tensor([4977, 4977, 1184, 2257, 4808,  255, 3949, 3564, 2707,  629, 4082, 3410,\n        3710, 3607,  243, 4978, 4978])\nSequence 4: tensor([4977, 4977,   82,  706, 1372, 1762, 4978, 4978])\nSequence 5: tensor([4977, 4977, 3506, 1667, 3506, 2993, 3898,   63, 3789, 4658, 4584, 1205,\n        1183, 4978, 4978])\n\n5 premières séquences encodées de Y_train_encoded :\nSequence 1: tensor([13362, 13362, 10264, 10505,  2364, 13363, 13363])\nSequence 2: tensor([13362, 13362, 12134, 13363, 13363])\nSequence 3: tensor([13362, 13362,  6500,  5125,  5732, 10329,  3253,  4108,  3030,  8601,\n         4108,  6214,  3725, 13363, 13363])\nSequence 4: tensor([13362, 13362,  8157,  5158, 13363, 13363])\nSequence 5: tensor([13362, 13362,  2055,  5548,  7910,  2510,  4108, 11083,  6134, 13363,\n        13363])\n\n5 premières séquences padées de X_train_padded :\nSequence 1: [4977, 4977, 2700, 1372, 1064, 3949, 4082, 4881, 3607, 4535, 4978, 4978, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSequence 2: [4977, 4977, 2242, 4978, 4978, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSequence 3: [4977, 4977, 1184, 2257, 4808, 255, 3949, 3564, 2707, 629, 4082, 3410, 3710, 3607, 243, 4978, 4978, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSequence 4: [4977, 4977, 82, 706, 1372, 1762, 4978, 4978, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSequence 5: [4977, 4977, 3506, 1667, 3506, 2993, 3898, 63, 3789, 4658, 4584, 1205, 1183, 4978, 4978, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\n5 premières séquences padées de Y_train_padded :\nSequence 1: [13362, 13362, 10264, 10505, 2364, 13363, 13363, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSequence 2: [13362, 13362, 12134, 13363, 13363, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSequence 3: [13362, 13362, 6500, 5125, 5732, 10329, 3253, 4108, 3030, 8601, 4108, 6214, 3725, 13363, 13363, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSequence 4: [13362, 13362, 8157, 5158, 13363, 13363, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nSequence 5: [13362, 13362, 2055, 5548, 7910, 2510, 4108, 11083, 6134, 13363, 13363, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":129},{"cell_type":"markdown","source":"LSTM Model Implementation","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Define VanillaLSTMCell as per the given equations\nclass VanillaLSTMCell(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(VanillaLSTMCell, self).__init__()\n        self.hidden_size = hidden_size\n\n        # Input gate parameters\n        self.Wxi = nn.Linear(input_size, hidden_size)\n        self.Whi = nn.Linear(hidden_size, hidden_size)\n        self.bi = nn.Parameter(torch.zeros(hidden_size))\n\n        # Forget gate parameters\n        self.Wxf = nn.Linear(input_size, hidden_size)\n        self.Whf = nn.Linear(hidden_size, hidden_size)\n        self.bf = nn.Parameter(torch.zeros(hidden_size))\n\n        # Output gate parameters\n        self.Wxo = nn.Linear(input_size, hidden_size)\n        self.Who = nn.Linear(hidden_size, hidden_size)\n        self.bo = nn.Parameter(torch.zeros(hidden_size))\n\n        # Cell gate (g_t) parameters\n        self.Wxg = nn.Linear(input_size, hidden_size)\n        self.Whg = nn.Linear(hidden_size, hidden_size)\n        self.bc = nn.Parameter(torch.zeros(hidden_size))\n\n    def forward(self, x_t, prev_state):\n        h_prev, c_prev = prev_state\n\n        # Compute gates\n        i_t = torch.sigmoid(self.Whi(h_prev) + self.Wxi(x_t) + self.bi)\n        f_t = torch.sigmoid(self.Whf(h_prev) + self.Wxf(x_t) + self.bf)\n        o_t = torch.sigmoid(self.Who(h_prev) + self.Wxo(x_t) + self.bo)\n        g_t = torch.tanh(self.Whg(h_prev) + self.Wxg(x_t) + self.bc)\n\n        # Compute cell state and hidden state\n        c_t = f_t * c_prev + i_t * g_t\n        h_t = o_t * torch.tanh(g_t)\n\n        return h_t, c_t\n\n# Define the Seq2Seq model using VanillaLSTMCell\nclass LSTMSeq2Seq(nn.Module):\n    def __init__(self, input_dim, output_dim, embed_dim, hidden_dim, n_layers):\n        super(LSTMSeq2Seq, self).__init__()\n        self.embed_dim = embed_dim\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n\n        self.encoder_embedding = nn.Embedding(input_dim, embed_dim)\n        self.decoder_embedding = nn.Embedding(output_dim, embed_dim)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n        # Encoder and Decoder use VanillaLSTMCell\n        self.encoder_cells = nn.ModuleList([VanillaLSTMCell(embed_dim if i == 0 else hidden_dim, hidden_dim) for i in range(n_layers)])\n        self.decoder_cells = nn.ModuleList([VanillaLSTMCell(embed_dim if i == 0 else hidden_dim, hidden_dim) for i in range(n_layers)])\n\n    def forward(self, source, target):\n        batch_size = source.size(0)\n        seq_len = target.size(1)\n\n        # Embedding for the encoder\n        encoder_input = self.encoder_embedding(source)\n\n        # Initialize states\n        h, c = [torch.zeros(batch_size, self.hidden_dim).to(encoder_input.device) for _ in range(self.n_layers)], \\\n               [torch.zeros(batch_size, self.hidden_dim).to(encoder_input.device) for _ in range(self.n_layers)]\n\n        # Encoder\n        for t in range(source.size(1)):\n            x_t = encoder_input[:, t, :]\n            for i, cell in enumerate(self.encoder_cells):\n                h[i], c[i] = cell(x_t, (h[i], c[i]))\n                x_t = h[i]  # Pass the hidden state to the next layer\n\n        # Initialize decoder states with encoder final states\n        decoder_input = self.decoder_embedding(target[:, 0])  # Feed <SOS> token at the first timestep\n        outputs = []\n\n        for t in range(seq_len - 1):  # Exclude the last token in target\n            for i, cell in enumerate(self.decoder_cells):\n                h[i], c[i] = cell(decoder_input, (h[i], c[i]))\n                decoder_input = h[i]  # Feed the current hidden state to the next layer\n\n            # Get the output\n            outputs.append(self.fc(decoder_input))  # Output for current timestep\n\n            if t < seq_len - 1:  # Teacher forcing: use the target token for the next time step\n                decoder_input = self.decoder_embedding(target[:, t + 1])\n\n        # Stack outputs\n        outputs = torch.stack(outputs, dim=1)\n        return outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:24.649377Z","iopub.execute_input":"2024-12-09T22:07:24.649734Z","iopub.status.idle":"2024-12-09T22:07:24.665453Z","shell.execute_reply.started":"2024-12-09T22:07:24.649705Z","shell.execute_reply":"2024-12-09T22:07:24.664494Z"}},"outputs":[],"execution_count":130},{"cell_type":"code","source":"print(f\"input_dim: {input_dim}, word_to_ix_eng size: {len(word_to_ix_eng)}\")\nprint(f\"output_dim: {output_dim}, word_to_ix_dari size: {len(word_to_ix_dari)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:28.324920Z","iopub.execute_input":"2024-12-09T22:07:28.325281Z","iopub.status.idle":"2024-12-09T22:07:28.330085Z","shell.execute_reply.started":"2024-12-09T22:07:28.325239Z","shell.execute_reply":"2024-12-09T22:07:28.329227Z"}},"outputs":[{"name":"stdout","text":"input_dim: 4979, word_to_ix_eng size: 4979\noutput_dim: 13364, word_to_ix_dari size: 13364\n","output_type":"stream"}],"execution_count":131},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Create TensorDatasets for train, validation, and test\ntrain_dataset = TensorDataset(X_train_padded, Y_train_padded)\nval_dataset = TensorDataset(X_val_padded, Y_val_padded)\ntest_dataset = TensorDataset(X_test_padded, Y_test_padded)\n\n# Create DataLoaders\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Define model parameters\ninput_dim = len(word_to_ix_eng)  # Vocabulary size of English\noutput_dim = len(word_to_ix_dari)  # Vocabulary size of Darija\nembed_dim = 256  # Embedding size\nhidden_dim = 512  # Hidden layer size\nn_layers = 2  # Number of LSTM layers\nlr=0.001\n\n# Initialize model, loss, and optimizer\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = LSTMSeq2Seq(input_dim, output_dim, embed_dim, hidden_dim, n_layers).to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=word_to_ix_dari[\"<PAD>\"])  # Ignore PAD tokens in the loss\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 20\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_loss = 0\n    \n    for batch in train_loader:\n        source, target = batch\n        source, target = source.to(device), target.to(device)\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        output = model(source, target)\n        \n        # Reshape output and target for loss computation\n        output = output.view(-1, output_dim)  # Flatten predictions\n        target = target[:, 1:].contiguous().view(-1)  # Flatten target, exclude <SOS> token\n\n        # Compute loss and backpropagate\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n\n    # Validation loss (optional)\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            source, target = batch\n            source, target = source.to(device), target.to(device)\n\n            output = model(source, target)\n            output = output.view(-1, output_dim)\n            target = target[:, 1:].contiguous().view(-1)\n\n            val_loss += criterion(output, target).item()\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_loss / len(train_loader):.4f}, Validation Loss: {val_loss / len(val_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T20:45:58.110464Z","iopub.execute_input":"2024-12-09T20:45:58.111053Z","iopub.status.idle":"2024-12-09T20:53:15.528789Z","shell.execute_reply.started":"2024-12-09T20:45:58.111021Z","shell.execute_reply":"2024-12-09T20:53:15.527998Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20, Train Loss: 5.4781, Validation Loss: 5.1966\nEpoch 2/20, Train Loss: 4.8811, Validation Loss: 5.2758\nEpoch 3/20, Train Loss: 4.7316, Validation Loss: 5.3133\nEpoch 4/20, Train Loss: 4.5752, Validation Loss: 5.3121\nEpoch 5/20, Train Loss: 4.3887, Validation Loss: 5.3861\nEpoch 6/20, Train Loss: 4.1529, Validation Loss: 5.4817\nEpoch 7/20, Train Loss: 3.8665, Validation Loss: 5.5950\nEpoch 8/20, Train Loss: 3.5235, Validation Loss: 5.7382\nEpoch 9/20, Train Loss: 3.1559, Validation Loss: 5.8747\nEpoch 10/20, Train Loss: 2.7731, Validation Loss: 6.0137\nEpoch 11/20, Train Loss: 2.4187, Validation Loss: 6.1691\nEpoch 12/20, Train Loss: 2.1212, Validation Loss: 6.3103\nEpoch 13/20, Train Loss: 1.8920, Validation Loss: 6.3907\nEpoch 14/20, Train Loss: 1.7238, Validation Loss: 6.5345\nEpoch 15/20, Train Loss: 1.6033, Validation Loss: 6.6026\nEpoch 16/20, Train Loss: 1.5259, Validation Loss: 6.7041\nEpoch 17/20, Train Loss: 1.4747, Validation Loss: 6.7427\nEpoch 18/20, Train Loss: 1.4420, Validation Loss: 6.7666\nEpoch 19/20, Train Loss: 1.4194, Validation Loss: 6.7917\nEpoch 20/20, Train Loss: 1.4059, Validation Loss: 6.8160\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T17:06:03.325748Z","iopub.execute_input":"2024-12-09T17:06:03.327101Z","iopub.status.idle":"2024-12-09T17:06:03.332611Z","shell.execute_reply.started":"2024-12-09T17:06:03.327051Z","shell.execute_reply":"2024-12-09T17:06:03.331839Z"}},"outputs":[{"name":"stdout","text":"LSTMSeq2Seq(\n  (encoder_embedding): Embedding(4979, 256)\n  (decoder_embedding): Embedding(13364, 256)\n  (fc): Linear(in_features=512, out_features=13364, bias=True)\n  (encoder_cells): ModuleList(\n    (0): VanillaLSTMCell(\n      (Wxi): Linear(in_features=256, out_features=512, bias=True)\n      (Whi): Linear(in_features=512, out_features=512, bias=True)\n      (Wxf): Linear(in_features=256, out_features=512, bias=True)\n      (Whf): Linear(in_features=512, out_features=512, bias=True)\n      (Wxo): Linear(in_features=256, out_features=512, bias=True)\n      (Who): Linear(in_features=512, out_features=512, bias=True)\n      (Wxg): Linear(in_features=256, out_features=512, bias=True)\n      (Whg): Linear(in_features=512, out_features=512, bias=True)\n    )\n    (1): VanillaLSTMCell(\n      (Wxi): Linear(in_features=512, out_features=512, bias=True)\n      (Whi): Linear(in_features=512, out_features=512, bias=True)\n      (Wxf): Linear(in_features=512, out_features=512, bias=True)\n      (Whf): Linear(in_features=512, out_features=512, bias=True)\n      (Wxo): Linear(in_features=512, out_features=512, bias=True)\n      (Who): Linear(in_features=512, out_features=512, bias=True)\n      (Wxg): Linear(in_features=512, out_features=512, bias=True)\n      (Whg): Linear(in_features=512, out_features=512, bias=True)\n    )\n  )\n  (decoder_cells): ModuleList(\n    (0): VanillaLSTMCell(\n      (Wxi): Linear(in_features=256, out_features=512, bias=True)\n      (Whi): Linear(in_features=512, out_features=512, bias=True)\n      (Wxf): Linear(in_features=256, out_features=512, bias=True)\n      (Whf): Linear(in_features=512, out_features=512, bias=True)\n      (Wxo): Linear(in_features=256, out_features=512, bias=True)\n      (Who): Linear(in_features=512, out_features=512, bias=True)\n      (Wxg): Linear(in_features=256, out_features=512, bias=True)\n      (Whg): Linear(in_features=512, out_features=512, bias=True)\n    )\n    (1): VanillaLSTMCell(\n      (Wxi): Linear(in_features=512, out_features=512, bias=True)\n      (Whi): Linear(in_features=512, out_features=512, bias=True)\n      (Wxf): Linear(in_features=512, out_features=512, bias=True)\n      (Whf): Linear(in_features=512, out_features=512, bias=True)\n      (Wxo): Linear(in_features=512, out_features=512, bias=True)\n      (Who): Linear(in_features=512, out_features=512, bias=True)\n      (Wxg): Linear(in_features=512, out_features=512, bias=True)\n      (Whg): Linear(in_features=512, out_features=512, bias=True)\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Chemin pour sauvegarder le modèle\nmodel_path = \"/kaggle/working/lstm_seq2seq_model.pth\"\n\n# Sauvegarder le modèle\ntorch.save({\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'input_dim': input_dim,\n    'output_dim': output_dim,\n    'embed_dim': embed_dim,\n    'hidden_dim': hidden_dim,\n    'n_layers': n_layers,\n}, model_path)\n\nprint(f\"Modèle sauvegardé dans {model_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T17:12:52.232426Z","iopub.execute_input":"2024-12-09T17:12:52.233335Z","iopub.status.idle":"2024-12-09T17:12:52.525944Z","shell.execute_reply.started":"2024-12-09T17:12:52.233294Z","shell.execute_reply":"2024-12-09T17:12:52.525039Z"}},"outputs":[{"name":"stdout","text":"Modèle sauvegardé dans /kaggle/working/lstm_seq2seq_model.pth\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"test","metadata":{}},{"cell_type":"code","source":"def translate_sentence(sentence, model, word_to_ix_eng, word_to_ix_dari, ix_to_word_dari, max_length=50):\n    # Preprocess and tokenize the sentence\n    tokens = sentence.lower().split()  # Tokenize and lowercase\n    tokens = [word_to_ix_eng.get(word, word_to_ix_eng['<UNK>']) for word in tokens]  # Convert to indices\n    tokens = [word_to_ix_eng['<SOS>']] + tokens + [word_to_ix_eng['<EOS>']]  # Add <SOS> and <EOS>\n    \n    # Convert to tensor and move to device\n    input_tensor = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)  # Add batch dimension\n\n    model.eval()\n    with torch.no_grad():\n        # Encoder forward pass\n        batch_size = input_tensor.size(0)\n        encoder_input = model.encoder_embedding(input_tensor)\n        h, c = [torch.zeros(batch_size, model.hidden_dim).to(device) for _ in range(model.n_layers)], \\\n               [torch.zeros(batch_size, model.hidden_dim).to(device) for _ in range(model.n_layers)]\n        \n        for t in range(input_tensor.size(1)):\n            x_t = encoder_input[:, t, :]\n            for i, cell in enumerate(model.encoder_cells):\n                h[i], c[i] = cell(x_t, (h[i], c[i]))\n                x_t = h[i]  # Pass the hidden state to the next layer\n\n        # Decoder initialization\n        decoder_input = torch.tensor([word_to_ix_dari['<SOS>']], dtype=torch.long).to(device)  # Start with <SOS>\n        decoder_input = model.decoder_embedding(decoder_input).unsqueeze(0)  # Add batch dimension\n        translated_sentence = []\n\n        for _ in range(max_length):\n            for i, cell in enumerate(model.decoder_cells):\n                h[i], c[i] = cell(decoder_input.squeeze(1), (h[i], c[i]))\n                decoder_input = h[i]  # Feed the current hidden state to the next layer\n\n            output_logits = model.fc(decoder_input)  # Compute output\n            predicted_idx = torch.argmax(output_logits, dim=-1).item()  # Get index of the predicted word\n\n            if predicted_idx == word_to_ix_dari['<EOS>']:\n                break  # Stop if <EOS> is predicted\n\n            translated_sentence.append(ix_to_word_dari[predicted_idx])  # Convert index to word\n            decoder_input = model.decoder_embedding(torch.tensor([predicted_idx], dtype=torch.long).to(device)).unsqueeze(0)\n\n    return ' '.join(translated_sentence)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T21:12:33.841787Z","iopub.execute_input":"2024-12-09T21:12:33.842691Z","iopub.status.idle":"2024-12-09T21:12:33.852722Z","shell.execute_reply.started":"2024-12-09T21:12:33.842658Z","shell.execute_reply":"2024-12-09T21:12:33.851631Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"ix_to_word_dari = {index: word for word, index in word_to_ix_dari.items()}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T21:12:03.733617Z","iopub.execute_input":"2024-12-09T21:12:03.734008Z","iopub.status.idle":"2024-12-09T21:12:03.740618Z","shell.execute_reply.started":"2024-12-09T21:12:03.733976Z","shell.execute_reply":"2024-12-09T21:12:03.739662Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"test_sentence = \"are you new to this neighborhood\"\ntranslated_sentence = translate_sentence(test_sentence, model, word_to_ix_eng, word_to_ix_dari, ix_to_word_dari)\nprint(f\"Translated: {translated_sentence}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:10:56.955774Z","iopub.execute_input":"2024-12-09T22:10:56.956167Z","iopub.status.idle":"2024-12-09T22:10:56.977977Z","shell.execute_reply.started":"2024-12-09T22:10:56.956126Z","shell.execute_reply":"2024-12-09T22:10:56.977226Z"}},"outputs":[{"name":"stdout","text":"Translated: <SOS> wach nta jdid fhad l7ay\n","output_type":"stream"}],"execution_count":134},{"cell_type":"code","source":"test_sentence = \"hand me that bag\"\ntranslated_sentence = translate_sentence(test_sentence, model3, word_to_ix_eng, word_to_ix_dari, ix_to_word_dari)\nprint(f\"Translated: {translated_sentence}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T21:19:51.782918Z","iopub.execute_input":"2024-12-09T21:19:51.783277Z","iopub.status.idle":"2024-12-09T21:19:51.795248Z","shell.execute_reply.started":"2024-12-09T21:19:51.783248Z","shell.execute_reply":"2024-12-09T21:19:51.794372Z"}},"outputs":[{"name":"stdout","text":"Translated: <SOS> wach nta katakhod\n","output_type":"stream"}],"execution_count":93},{"cell_type":"code","source":"test_sentence = \"where are you\"\ntranslated_sentence = translate_sentence(test_sentence, model3, word_to_ix_eng, word_to_ix_dari, ix_to_word_dari)\nprint(f\"Translated: {translated_sentence}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:12:06.264817Z","iopub.execute_input":"2024-12-09T22:12:06.265524Z","iopub.status.idle":"2024-12-09T22:12:06.277218Z","shell.execute_reply.started":"2024-12-09T22:12:06.265490Z","shell.execute_reply":"2024-12-09T22:12:06.276371Z"}},"outputs":[{"name":"stdout","text":"Translated: <SOS> wach nta\n","output_type":"stream"}],"execution_count":136},{"cell_type":"code","source":"test_sentence = \"So the first thing you do is choose\"\ntranslated_sentence = translate_sentence(test_sentence, model2, word_to_ix_eng, word_to_ix_dari, ix_to_word_dari)\nprint(f\"Translated: {translated_sentence}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T21:23:10.896052Z","iopub.execute_input":"2024-12-09T21:23:10.896398Z","iopub.status.idle":"2024-12-09T21:23:10.914194Z","shell.execute_reply.started":"2024-12-09T21:23:10.896365Z","shell.execute_reply":"2024-12-09T21:23:10.913345Z"}},"outputs":[{"name":"stdout","text":"Translated: <SOS> wach 3ndk chi blassa katmchi liha fach kat7ss brassk machi houa hadak\n","output_type":"stream"}],"execution_count":101},{"cell_type":"code","source":"test_sentences = [\"how are you\", \"what is your name\", \"I am learning AI\", \"hello\",\"\"]\n\nfor sentence in test_sentences:\n    translated_sentence = translate_sentence(sentence, model, word_to_ix_eng, word_to_ix_dari, ix_to_word_dari)\n    print(f\"Anglais : {sentence} => Darija : {translated_sentence}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T17:42:03.147777Z","iopub.execute_input":"2024-12-09T17:42:03.148436Z","iopub.status.idle":"2024-12-09T17:42:03.210692Z","shell.execute_reply.started":"2024-12-09T17:42:03.148404Z","shell.execute_reply":"2024-12-09T17:42:03.209887Z"}},"outputs":[{"name":"stdout","text":"Anglais : how are you => Darija : <SOS> wach kayn nabid ma7ali bchkal khaS\nAnglais : what is your name => Darija : <SOS> wach nta wajd\nAnglais : I am learning AI => Darija : <SOS> wach kayn nabid ma7ali bchkal khaS\nAnglais : hello => Darija : <SOS> wach kayn nabid ma7ali bchkal khaS\nAnglais :  => Darija : <SOS> wach kayn nabid ma7ali bchkal khaS\n","output_type":"stream"}],"execution_count":80},{"cell_type":"markdown","source":"model 2 changing hyperparams","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Create TensorDatasets for train, validation, and test\ntrain_dataset = TensorDataset(X_train_padded, Y_train_padded)\nval_dataset = TensorDataset(X_val_padded, Y_val_padded)\ntest_dataset = TensorDataset(X_test_padded, Y_test_padded)\n\n# Create DataLoaders\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n\n# Define model parameters\ninput_dim = len(word_to_ix_eng)  # Vocabulary size of English\noutput_dim = len(word_to_ix_dari)  # Vocabulary size of Darija\nembed_dim = 64  # Embedding size\nhidden_dim2 = 128  # Hidden layer size\nn_layers = 1  # Number of LSTM layers\nlr=0.0001\n\n# Initialize model, loss, and optimizer\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel2 = LSTMSeq2Seq(input_dim, output_dim, embed_dim, hidden_dim, n_layers).to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=word_to_ix_dari[\"<PAD>\"])  # Ignore PAD tokens in the loss\noptimizer = optim.Adam(model2.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 15\nfor epoch in range(num_epochs):\n    model2.train()\n    epoch_loss = 0\n    \n    for batch in train_loader:\n        source, target = batch\n        source, target = source.to(device), target.to(device)\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        output = model2(source, target)\n        \n        # Reshape output and target for loss computation\n        output = output.view(-1, output_dim)  # Flatten predictions\n        target = target[:, 1:].contiguous().view(-1)  # Flatten target, exclude <SOS> token\n\n        # Compute loss and backpropagate\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n\n    # Validation loss (optional)\n    model2.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            source, target = batch\n            source, target = source.to(device), target.to(device)\n\n            output = model2(source, target)\n            output = output.view(-1, output_dim)\n            target = target[:, 1:].contiguous().view(-1)\n\n            val_loss += criterion(output, target).item()\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_loss / len(train_loader):.4f}, Validation Loss: {val_loss / len(val_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:07:55.892960Z","iopub.execute_input":"2024-12-09T22:07:55.893317Z","iopub.status.idle":"2024-12-09T22:10:56.954040Z","shell.execute_reply.started":"2024-12-09T22:07:55.893285Z","shell.execute_reply":"2024-12-09T22:10:56.953159Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15, Train Loss: 6.2453, Validation Loss: 5.2595\nEpoch 2/15, Train Loss: 4.9672, Validation Loss: 5.2891\nEpoch 3/15, Train Loss: 4.8273, Validation Loss: 5.3159\nEpoch 4/15, Train Loss: 4.6952, Validation Loss: 5.3195\nEpoch 5/15, Train Loss: 4.5541, Validation Loss: 5.3403\nEpoch 6/15, Train Loss: 4.4071, Validation Loss: 5.3334\nEpoch 7/15, Train Loss: 4.2531, Validation Loss: 5.3632\nEpoch 8/15, Train Loss: 4.0984, Validation Loss: 5.3863\nEpoch 9/15, Train Loss: 3.9473, Validation Loss: 5.4109\nEpoch 10/15, Train Loss: 3.7981, Validation Loss: 5.4299\nEpoch 11/15, Train Loss: 3.6548, Validation Loss: 5.4604\nEpoch 12/15, Train Loss: 3.5152, Validation Loss: 5.4940\nEpoch 13/15, Train Loss: 3.3826, Validation Loss: 5.5363\nEpoch 14/15, Train Loss: 3.2551, Validation Loss: 5.5631\nEpoch 15/15, Train Loss: 3.1316, Validation Loss: 5.5999\n","output_type":"stream"}],"execution_count":133},{"cell_type":"code","source":"print(model2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"model 3 ","metadata":{}},{"cell_type":"code","source":"# Training Setup\nbatch_size = 64\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\ntrain_loader = DataLoader(TensorDataset(X_train_padded, Y_train_padded), batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(TensorDataset(X_val_padded, Y_val_padded), batch_size=batch_size, shuffle=False)\n\ninput_dim = len(word_to_ix_eng)\noutput_dim = len(word_to_ix_dari)\nembed_dim = 64\nhidden_dim = 128\nn_layers = 1\nlr=0.001\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel3 = LSTMSeq2Seq(input_dim, output_dim, embed_dim, hidden_dim, n_layers).to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=word_to_ix_dari[\"<PAD>\"])\noptimizer = optim.Adam(model3.parameters(), lr=0.001)\n\nnum_epochs = 15\nfor epoch in range(num_epochs):\n    model3.train()\n    epoch_loss = 0\n\n    for source, target in train_loader:\n        source, target = source.to(device), target.to(device)\n\n        optimizer.zero_grad()\n        output = model3(source, target)\n        output = output.view(-1, output_dim)\n        target = target[:, 1:].contiguous().view(-1)\n\n        loss = criterion(output, target)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model3.parameters(), max_norm=1.0)\n        optimizer.step()\n        epoch_loss += loss.item()\n\n    val_loss = 0\n    model3.eval()\n    with torch.no_grad():\n        for source, target in val_loader:\n            source, target = source.to(device), target.to(device)\n            output = model3(source, target)\n            output = output.view(-1, output_dim)\n            target = target[:, 1:].contiguous().view(-1)\n            val_loss += criterion(output, target).item()\n\n    avg_val_loss = val_loss / len(val_loader)  # Compute avg_val_loss before using it\n    scheduler.step(avg_val_loss)  # Pass avg_val_loss to the scheduler\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_loss / len(train_loader):.4f}, Validation Loss: {avg_val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T20:39:21.844793Z","iopub.execute_input":"2024-12-09T20:39:21.845564Z","iopub.status.idle":"2024-12-09T20:42:18.578162Z","shell.execute_reply.started":"2024-12-09T20:39:21.845532Z","shell.execute_reply":"2024-12-09T20:42:18.577203Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15, Train Loss: 6.3758, Validation Loss: 5.2577\nEpoch 2/15, Train Loss: 4.9536, Validation Loss: 5.3045\nEpoch 3/15, Train Loss: 4.8059, Validation Loss: 5.3305\nEpoch 4/15, Train Loss: 4.6616, Validation Loss: 5.3361\nEpoch 5/15, Train Loss: 4.5085, Validation Loss: 5.3608\nEpoch 6/15, Train Loss: 4.3543, Validation Loss: 5.3721\nEpoch 7/15, Train Loss: 4.1993, Validation Loss: 5.3927\nEpoch 8/15, Train Loss: 4.0429, Validation Loss: 5.4303\nEpoch 9/15, Train Loss: 3.8928, Validation Loss: 5.4450\nEpoch 10/15, Train Loss: 3.7462, Validation Loss: 5.4685\nEpoch 11/15, Train Loss: 3.6041, Validation Loss: 5.5011\nEpoch 12/15, Train Loss: 3.4667, Validation Loss: 5.5429\nEpoch 13/15, Train Loss: 3.3362, Validation Loss: 5.5791\nEpoch 14/15, Train Loss: 3.2095, Validation Loss: 5.6105\nEpoch 15/15, Train Loss: 3.0911, Validation Loss: 5.6492\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"# Training Setup\nbatch_size = 64\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\ntrain_loader = DataLoader(TensorDataset(X_train_padded, Y_train_padded), batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(TensorDataset(X_val_padded, Y_val_padded), batch_size=batch_size, shuffle=False)\n\ninput_dim = len(word_to_ix_eng)\noutput_dim = len(word_to_ix_dari)\nembed_dim = 512\nhidden_dim = 512\nn_layers = 5\nlr=0.001\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel3 = LSTMSeq2Seq(input_dim, output_dim, embed_dim, hidden_dim, n_layers).to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=word_to_ix_dari[\"<PAD>\"])\noptimizer = optim.Adam(model3.parameters(), lr=0.001)\n\nnum_epochs = 15\nfor epoch in range(num_epochs):\n    model3.train()\n    epoch_loss = 0\n\n    for source, target in train_loader:\n        source, target = source.to(device), target.to(device)\n\n        optimizer.zero_grad()\n        output = model3(source, target)\n        output = output.view(-1, output_dim)\n        target = target[:, 1:].contiguous().view(-1)\n\n        loss = criterion(output, target)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model3.parameters(), max_norm=1.0)\n        optimizer.step()\n        epoch_loss += loss.item()\n\n    val_loss = 0\n    model3.eval()\n    with torch.no_grad():\n        for source, target in val_loader:\n            source, target = source.to(device), target.to(device)\n            output = model3(source, target)\n            output = output.view(-1, output_dim)\n            target = target[:, 1:].contiguous().view(-1)\n            val_loss += criterion(output, target).item()\n\n    avg_val_loss = val_loss / len(val_loader)  # Compute avg_val_loss before using it\n    scheduler.step(avg_val_loss)  # Pass avg_val_loss to the scheduler\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_loss / len(train_loader):.4f}, Validation Loss: {avg_val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T22:17:32.988688Z","iopub.execute_input":"2024-12-09T22:17:32.989388Z","iopub.status.idle":"2024-12-09T22:30:42.798635Z","shell.execute_reply.started":"2024-12-09T22:17:32.989357Z","shell.execute_reply":"2024-12-09T22:30:42.797755Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15, Train Loss: 5.5366, Validation Loss: 5.2606\nEpoch 2/15, Train Loss: 4.9086, Validation Loss: 5.3500\nEpoch 3/15, Train Loss: 4.7672, Validation Loss: 5.3798\nEpoch 4/15, Train Loss: 4.6350, Validation Loss: 5.4555\nEpoch 5/15, Train Loss: 4.5125, Validation Loss: 5.5186\nEpoch 6/15, Train Loss: 4.3849, Validation Loss: 5.6219\nEpoch 7/15, Train Loss: 4.2575, Validation Loss: 5.7511\nEpoch 8/15, Train Loss: 4.1436, Validation Loss: 5.8736\nEpoch 9/15, Train Loss: 4.0308, Validation Loss: 5.9787\nEpoch 10/15, Train Loss: 3.9315, Validation Loss: 6.1090\nEpoch 11/15, Train Loss: 3.8377, Validation Loss: 6.1317\nEpoch 12/15, Train Loss: 3.7421, Validation Loss: 6.2169\nEpoch 13/15, Train Loss: 3.6564, Validation Loss: 6.3159\nEpoch 14/15, Train Loss: 3.5821, Validation Loss: 6.3698\nEpoch 15/15, Train Loss: 3.5033, Validation Loss: 6.4415\n","output_type":"stream"}],"execution_count":137},{"cell_type":"code","source":"print(model3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T21:18:43.623243Z","iopub.execute_input":"2024-12-09T21:18:43.623967Z","iopub.status.idle":"2024-12-09T21:18:43.628539Z","shell.execute_reply.started":"2024-12-09T21:18:43.623924Z","shell.execute_reply":"2024-12-09T21:18:43.627709Z"}},"outputs":[{"name":"stdout","text":"LSTMSeq2Seq(\n  (encoder_embedding): Embedding(4979, 64)\n  (decoder_embedding): Embedding(13364, 64)\n  (fc): Linear(in_features=128, out_features=13364, bias=True)\n  (encoder_cells): ModuleList(\n    (0): VanillaLSTMCell(\n      (Wxi): Linear(in_features=64, out_features=128, bias=True)\n      (Whi): Linear(in_features=128, out_features=128, bias=True)\n      (Wxf): Linear(in_features=64, out_features=128, bias=True)\n      (Whf): Linear(in_features=128, out_features=128, bias=True)\n      (Wxo): Linear(in_features=64, out_features=128, bias=True)\n      (Who): Linear(in_features=128, out_features=128, bias=True)\n      (Wxg): Linear(in_features=64, out_features=128, bias=True)\n      (Whg): Linear(in_features=128, out_features=128, bias=True)\n    )\n  )\n  (decoder_cells): ModuleList(\n    (0): VanillaLSTMCell(\n      (Wxi): Linear(in_features=64, out_features=128, bias=True)\n      (Whi): Linear(in_features=128, out_features=128, bias=True)\n      (Wxf): Linear(in_features=64, out_features=128, bias=True)\n      (Whf): Linear(in_features=128, out_features=128, bias=True)\n      (Wxo): Linear(in_features=64, out_features=128, bias=True)\n      (Who): Linear(in_features=128, out_features=128, bias=True)\n      (Wxg): Linear(in_features=64, out_features=128, bias=True)\n      (Whg): Linear(in_features=128, out_features=128, bias=True)\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"print(model2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T21:24:57.446517Z","iopub.execute_input":"2024-12-09T21:24:57.446890Z","iopub.status.idle":"2024-12-09T21:24:57.451963Z","shell.execute_reply.started":"2024-12-09T21:24:57.446849Z","shell.execute_reply":"2024-12-09T21:24:57.450902Z"}},"outputs":[{"name":"stdout","text":"LSTMSeq2Seq(\n  (encoder_embedding): Embedding(4979, 64)\n  (decoder_embedding): Embedding(13364, 64)\n  (fc): Linear(in_features=512, out_features=13364, bias=True)\n  (encoder_cells): ModuleList(\n    (0): VanillaLSTMCell(\n      (Wxi): Linear(in_features=64, out_features=512, bias=True)\n      (Whi): Linear(in_features=512, out_features=512, bias=True)\n      (Wxf): Linear(in_features=64, out_features=512, bias=True)\n      (Whf): Linear(in_features=512, out_features=512, bias=True)\n      (Wxo): Linear(in_features=64, out_features=512, bias=True)\n      (Who): Linear(in_features=512, out_features=512, bias=True)\n      (Wxg): Linear(in_features=64, out_features=512, bias=True)\n      (Whg): Linear(in_features=512, out_features=512, bias=True)\n    )\n  )\n  (decoder_cells): ModuleList(\n    (0): VanillaLSTMCell(\n      (Wxi): Linear(in_features=64, out_features=512, bias=True)\n      (Whi): Linear(in_features=512, out_features=512, bias=True)\n      (Wxf): Linear(in_features=64, out_features=512, bias=True)\n      (Whf): Linear(in_features=512, out_features=512, bias=True)\n      (Wxo): Linear(in_features=64, out_features=512, bias=True)\n      (Who): Linear(in_features=512, out_features=512, bias=True)\n      (Wxg): Linear(in_features=64, out_features=512, bias=True)\n      (Whg): Linear(in_features=512, out_features=512, bias=True)\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":102},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T21:18:37.651821Z","iopub.execute_input":"2024-12-09T21:18:37.652201Z","iopub.status.idle":"2024-12-09T21:18:37.657192Z","shell.execute_reply.started":"2024-12-09T21:18:37.652171Z","shell.execute_reply":"2024-12-09T21:18:37.656274Z"}},"outputs":[{"name":"stdout","text":"LSTMSeq2Seq(\n  (encoder_embedding): Embedding(4979, 256)\n  (decoder_embedding): Embedding(13364, 256)\n  (fc): Linear(in_features=512, out_features=13364, bias=True)\n  (encoder_cells): ModuleList(\n    (0): VanillaLSTMCell(\n      (Wxi): Linear(in_features=256, out_features=512, bias=True)\n      (Whi): Linear(in_features=512, out_features=512, bias=True)\n      (Wxf): Linear(in_features=256, out_features=512, bias=True)\n      (Whf): Linear(in_features=512, out_features=512, bias=True)\n      (Wxo): Linear(in_features=256, out_features=512, bias=True)\n      (Who): Linear(in_features=512, out_features=512, bias=True)\n      (Wxg): Linear(in_features=256, out_features=512, bias=True)\n      (Whg): Linear(in_features=512, out_features=512, bias=True)\n    )\n    (1): VanillaLSTMCell(\n      (Wxi): Linear(in_features=512, out_features=512, bias=True)\n      (Whi): Linear(in_features=512, out_features=512, bias=True)\n      (Wxf): Linear(in_features=512, out_features=512, bias=True)\n      (Whf): Linear(in_features=512, out_features=512, bias=True)\n      (Wxo): Linear(in_features=512, out_features=512, bias=True)\n      (Who): Linear(in_features=512, out_features=512, bias=True)\n      (Wxg): Linear(in_features=512, out_features=512, bias=True)\n      (Whg): Linear(in_features=512, out_features=512, bias=True)\n    )\n  )\n  (decoder_cells): ModuleList(\n    (0): VanillaLSTMCell(\n      (Wxi): Linear(in_features=256, out_features=512, bias=True)\n      (Whi): Linear(in_features=512, out_features=512, bias=True)\n      (Wxf): Linear(in_features=256, out_features=512, bias=True)\n      (Whf): Linear(in_features=512, out_features=512, bias=True)\n      (Wxo): Linear(in_features=256, out_features=512, bias=True)\n      (Who): Linear(in_features=512, out_features=512, bias=True)\n      (Wxg): Linear(in_features=256, out_features=512, bias=True)\n      (Whg): Linear(in_features=512, out_features=512, bias=True)\n    )\n    (1): VanillaLSTMCell(\n      (Wxi): Linear(in_features=512, out_features=512, bias=True)\n      (Whi): Linear(in_features=512, out_features=512, bias=True)\n      (Wxf): Linear(in_features=512, out_features=512, bias=True)\n      (Whf): Linear(in_features=512, out_features=512, bias=True)\n      (Wxo): Linear(in_features=512, out_features=512, bias=True)\n      (Who): Linear(in_features=512, out_features=512, bias=True)\n      (Wxg): Linear(in_features=512, out_features=512, bias=True)\n      (Whg): Linear(in_features=512, out_features=512, bias=True)\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":91},{"cell_type":"markdown","source":"**Advanced LSTM Cells**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass AdvancedLSTMCell(nn.Module):\n    def _init_(self, input_dim, hidden_dim, peephole=True, working_memory=True):\n        super(AdvancedLSTMCell, self)._init_()\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.peephole = peephole\n        self.working_memory = working_memory\n        \n        # Input gate parameters\n        self.Wxi = nn.Linear(input_dim, hidden_dim, bias=True)\n        self.Whi = nn.Linear(hidden_dim, hidden_dim, bias=False)\n        self.Wci = nn.Linear(hidden_dim, hidden_dim, bias=False) if peephole else None\n\n        # Forget gate parameters\n        self.Wxf = nn.Linear(input_dim, hidden_dim, bias=True)\n        self.Whf = nn.Linear(hidden_dim, hidden_dim, bias=False)\n        self.Wcf = nn.Linear(hidden_dim, hidden_dim, bias=False) if peephole else None\n\n        # Output gate parameters\n        self.Wxo = nn.Linear(input_dim, hidden_dim, bias=True)\n        self.Who = nn.Linear(hidden_dim, hidden_dim, bias=False)\n        self.Wco = nn.Linear(hidden_dim, hidden_dim, bias=False) if peephole else None\n\n        # Cell state parameters\n        self.Wxg = nn.Linear(input_dim, hidden_dim, bias=True)\n        self.Whg = nn.Linear(hidden_dim, hidden_dim, bias=False)\n\n    def forwardA(self, x, hidden):\n        h_prev, c_prev = hidden\n\n        # Working Memory Connections\n        if self.working_memory:\n            tanh_c_prev = torch.tanh(c_prev)\n            i = torch.sigmoid(self.Wxi(x) + self.Whi(h_prev) + self.Wci(c_prev) if self.peephole else self.Wxi(x) + self.Whi(h_prev) + tanh_c_prev)\n            f = torch.sigmoid(self.Wxf(x) + self.Whf(h_prev) + self.Wcf(c_prev) if self.peephole else self.Wxf(x) + self.Whf(h_prev) + tanh_c_prev)\n            o = torch.sigmoid(self.Wxo(x) + self.Who(h_prev) + self.Wco(c_prev) if self.peephole else self.Wxo(x) + self.Who(h_prev) + tanh_c_prev)\n        else:\n            i = torch.sigmoid(self.Wxi(x) + self.Whi(h_prev) + (self.Wci(c_prev) if self.peephole else 0))\n            f = torch.sigmoid(self.Wxf(x) + self.Whf(h_prev) + (self.Wcf(c_prev) if self.peephole else 0))\n            o = torch.sigmoid(self.Wxo(x) + self.Who(h_prev) + (self.Wco(c_prev) if self.peephole else 0))\n\n        # Compute the candidate cell state\n        g = torch.tanh(self.Wxg(x) + self.Whg(h_prev))\n        \n        # Compute the new cell state and hidden state\n        c_next = f * c_prev + i * g\n        h_next = o * torch.tanh(g)\n\n        return h_next, c_next","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T20:54:10.686777Z","iopub.execute_input":"2024-12-09T20:54:10.687108Z","iopub.status.idle":"2024-12-09T20:54:10.698204Z","shell.execute_reply.started":"2024-12-09T20:54:10.687083Z","shell.execute_reply":"2024-12-09T20:54:10.697316Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"class AdvancedLSTMEncoder(nn.Module):\n    def _init_(self, input_dim, embed_dim, hidden_dim, n_layers, peephole=False, working_memory=False):\n        super(AdvancedLSTMEncoder, self)._init_()\n        self.embedding = nn.Embedding(input_dim, embed_dim)\n        self.lstm_cells = nn.ModuleList(\n            [AdvancedLSTMCell(embed_dim if i == 0 else hidden_dim, hidden_dim, peephole, working_memory) for i in range(n_layers)]\n        )\n\n    def forward(self, x):\n        embedded = self.embedding(x)\n        h, c = [None] * len(self.lstm_cells), [None] * len(self.lstm_cells)\n        outputs = []\n        \n        for t in range(embedded.size(1)):\n            x_t = embedded[:, t, :]\n            for i, lstm_cell in enumerate(self.lstm_cells):\n                h_prev, c_prev = (h[i], c[i]) if h[i] is not None else (torch.zeros_like(x_t), torch.zeros_like(x_t))\n                h[i], c[i] = lstm_cell(x_t, (h_prev, c_prev))\n                x_t = h[i]\n            outputs.append(h[-1])\n\n        return torch.stack(outputs, dim=1), (h, c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T21:13:22.751265Z","iopub.execute_input":"2024-12-09T21:13:22.752123Z","iopub.status.idle":"2024-12-09T21:13:22.759252Z","shell.execute_reply.started":"2024-12-09T21:13:22.752093Z","shell.execute_reply":"2024-12-09T21:13:22.758356Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"class LSTMSeq2Seq(nn.Module):\n    def _init_(self, input_dim, output_dim, embed_dim, hidden_dim, n_layers,\n                 lstm_cell_type, peephole=False, working_memory=False):\n        super(LSTMSeq2Seq, self)._init_()\n        \n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.embed_dim = embed_dim\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n\n        # Embedding layers\n        self.encoder_embedding = nn.Embedding(input_dim, embed_dim)\n        self.decoder_embedding = nn.Embedding(output_dim, embed_dim)\n\n        # Encoder LSTM layers\n        self.encoder_cells = nn.ModuleList([\n            lstm_cell_type(embed_dim if i == 0 else hidden_dim, hidden_dim, \n                           peephole=peephole, working_memory=working_memory)\n            for i in range(n_layers)\n        ])\n        \n        # Decoder LSTM layers\n        self.decoder_cells = nn.ModuleList([\n            lstm_cell_type(embed_dim if i == 0 else hidden_dim, hidden_dim, \n                           peephole=peephole, working_memory=working_memory)\n            for i in range(n_layers)\n        ])\n        \n        # Fully connected output layer\n        self.fc = nn.Linear(hidden_dim, output_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T21:34:59.452875Z","iopub.execute_input":"2024-12-09T21:34:59.453227Z","iopub.status.idle":"2024-12-09T21:34:59.460024Z","shell.execute_reply.started":"2024-12-09T21:34:59.453192Z","shell.execute_reply":"2024-12-09T21:34:59.459152Z"}},"outputs":[],"execution_count":103},{"cell_type":"code","source":"# Define model with Advanced LSTM Cell\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninput_dim = len(word_to_ix_eng)\noutput_dim = len(word_to_ix_dari)\nembed_dim = 64\nhidden_dim = 128\nn_layers = 2\n\nmodel = LSTMSeq2Seq(\n    input_dim=input_dim,\n    output_dim=output_dim,\n    embed_dim=embed_dim,\n    hidden_dim=hidden_dim,\n    n_layers=n_layers,\n    lstm_cell_type=AdvancedLSTMCell,  # Use the advanced LSTM cell\n    peephole=True,  # Enable peephole connections\n    working_memory=True  # Enable working memory connections\n).to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=word_to_ix_dari['<PAD>'])\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n\n# Training and Validation\nnum_epochs = 15\nbatch_size = 64\ntrain_loader = DataLoader(TensorDataset(X_train_padded, Y_train_padded), batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(TensorDataset(X_val_padded, Y_val_padded), batch_size=batch_size, shuffle=False)\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    for source, target in train_loader:\n        source, target = source.to(device), target.to(device)\n\n        optimizer.zero_grad()\n        output = model(source, target)\n        output = output.view(-1, output_dim)\n        target = target[:, 1:].contiguous().view(-1)\n\n        loss = criterion(output, target)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        train_loss += loss.item()\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for source, target in val_loader:\n            source, target = source.to(device), target.to(device)\n            output = model(source, target)\n            output = output.view(-1, output_dim)\n            target = target[:, 1:].contiguous().view(-1)\n            val_loss += criterion(output, target).item()\n\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    scheduler.step(avg_val_loss)\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-09T21:37:07.815616Z","iopub.execute_input":"2024-12-09T21:37:07.816292Z","iopub.status.idle":"2024-12-09T21:37:07.861557Z","shell.execute_reply.started":"2024-12-09T21:37:07.816258Z","shell.execute_reply":"2024-12-09T21:37:07.860292Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[105], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m      7\u001b[0m n_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLSTMSeq2Seq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlstm_cell_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAdvancedLSTMCell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use the advanced LSTM cell\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeephole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Enable peephole connections\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworking_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Enable working memory connections\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39mword_to_ix_dari[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<PAD>\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     21\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:435\u001b[0m, in \u001b[0;36mModule.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# Backward compatibility: no args used to be allowed when call_super_init=False\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(kwargs):\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.__init__() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(args):\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.__init__() takes 1 positional argument but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m were\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m given\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: LSTMSeq2Seq.__init__() got an unexpected keyword argument 'input_dim'"],"ename":"TypeError","evalue":"LSTMSeq2Seq.__init__() got an unexpected keyword argument 'input_dim'","output_type":"error"}],"execution_count":105}]}